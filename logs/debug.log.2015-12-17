2015-12-17 14:47:45  [ main:0 ] - [ DEBUG ]  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
2015-12-17 14:47:45  [ main:43 ] - [ DEBUG ]  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
2015-12-17 14:47:45  [ main:45 ] - [ DEBUG ]  UgiMetrics, User and group related metrics
2015-12-17 14:47:46  [ main:651 ] - [ DEBUG ]  Kerberos krb5 configuration not found, setting default realm to empty
2015-12-17 14:47:46  [ main:653 ] - [ DEBUG ]   Creating new Groups object
2015-12-17 14:47:46  [ main:680 ] - [ DEBUG ]  Trying to load the custom-built native-hadoop library...
2015-12-17 14:47:46  [ main:703 ] - [ DEBUG ]  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-12-17 14:47:46  [ main:704 ] - [ DEBUG ]  java.library.path=C:\Program Files\Java\jdk1.8.0_60\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jre1.8.0_66/bin/server;C:/Program Files/Java/jre1.8.0_66/bin;C:/Program Files/Java/jre1.8.0_66/lib/amd64;C:\ProgramData\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Java\jdk1.8.0_60\bin;D:\developtools\maven\apache-maven-3.2.3-bin\apache-maven-3.2.3\bin;D:\Program Files (x86)\Git\cmd;D:\snapshot;D:\Program Files\TortoiseSVN\bin;D:\developtools\apache-ant-1.9.4\bin;D:\Program Files (x86)\scala\bin;C:\Program Files (x86)\scala\bin;D:\Program Files (x86)\OpenVPN\bin;D:\developtools\eclipse64\eclipse;;.
2015-12-17 14:47:46  [ main:704 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-12-17 14:47:46  [ main:704 ] - [ DEBUG ]  Falling back to shell based
2015-12-17 14:47:46  [ main:720 ] - [ DEBUG ]  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-12-17 14:47:46  [ main:721 ] - [ DEBUG ]  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
2015-12-17 14:47:46  [ main:784 ] - [ DEBUG ]  hadoop login
2015-12-17 14:47:46  [ main:802 ] - [ DEBUG ]  hadoop login commit
2015-12-17 14:47:46  [ main:831 ] - [ DEBUG ]  using local user:NTUserPrincipal: Administrator
2015-12-17 14:47:46  [ main:849 ] - [ DEBUG ]  UGI loginUser:Administrator (auth:SIMPLE)
2015-12-17 14:47:46  [ main:1459 ] - [ DEBUG ]  Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:225)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:250)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.conf.Configuration.getStrings(Configuration.java:1514)
	at org.apache.hadoop.hbase.zookeeper.ZKConfig.makeZKProps(ZKConfig.java:113)
	at org.apache.hadoop.hbase.zookeeper.ZKConfig.getZKQuorumServersString(ZKConfig.java:265)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:159)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:134)
	at org.apache.hadoop.hbase.client.ZooKeeperKeepAliveConnection.<init>(ZooKeeperKeepAliveConnection.java:43)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getKeepAliveZooKeeperWatcher(HConnectionManager.java:1769)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:82)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.retrieveClusterId(HConnectionManager.java:858)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.<init>(HConnectionManager.java:663)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:415)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:394)
	at org.apache.hadoop.hbase.client.HConnectionManager.getConnection(HConnectionManager.java:275)
	at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:197)
	at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:159)
	at com.ipinyou.tool.hbase.HBaseUtils.getFilterDate(HBaseUtils.java:134)
	at com.ipinyou.tool.hbase.HBaseUtils.main(HBaseUtils.java:170)
2015-12-17 14:47:46  [ main:1497 ] - [ ERROR ]  Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:278)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:300)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:293)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.conf.Configuration.getStrings(Configuration.java:1514)
	at org.apache.hadoop.hbase.zookeeper.ZKConfig.makeZKProps(ZKConfig.java:113)
	at org.apache.hadoop.hbase.zookeeper.ZKConfig.getZKQuorumServersString(ZKConfig.java:265)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:159)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:134)
	at org.apache.hadoop.hbase.client.ZooKeeperKeepAliveConnection.<init>(ZooKeeperKeepAliveConnection.java:43)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getKeepAliveZooKeeperWatcher(HConnectionManager.java:1769)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:82)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.retrieveClusterId(HConnectionManager.java:858)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.<init>(HConnectionManager.java:663)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:415)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:394)
	at org.apache.hadoop.hbase.client.HConnectionManager.getConnection(HConnectionManager.java:275)
	at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:197)
	at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:159)
	at com.ipinyou.tool.hbase.HBaseUtils.getFilterDate(HBaseUtils.java:134)
	at com.ipinyou.tool.hbase.HBaseUtils.main(HBaseUtils.java:170)
2015-12-17 14:47:47  [ main:1711 ] - [ INFO ]  Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2015-12-17 14:47:47  [ main:1711 ] - [ INFO ]  Client environment:host.name=10.1.2.39
2015-12-17 14:47:47  [ main:1711 ] - [ INFO ]  Client environment:java.version=1.8.0_60
2015-12-17 14:47:47  [ main:1711 ] - [ INFO ]  Client environment:java.vendor=Oracle Corporation
2015-12-17 14:47:47  [ main:1711 ] - [ INFO ]  Client environment:java.home=C:\Program Files\Java\jdk1.8.0_60\jre
2015-12-17 14:47:47  [ main:1711 ] - [ INFO ]  Client environment:java.class.path=E:\adunit\hadoop-tool\target\classes;E:\mavenrepository\log4j\log4j\1.2.14\log4j-1.2.14.jar;E:\mavenrepository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;E:\mavenrepository\org\apache\hbase\hbase-client\0.98.4-hadoop2\hbase-client-0.98.4-hadoop2.jar;E:\mavenrepository\org\apache\hbase\hbase-common\0.98.4-hadoop2\hbase-common-0.98.4-hadoop2.jar;E:\mavenrepository\org\apache\hbase\hbase-protocol\0.98.4-hadoop2\hbase-protocol-0.98.4-hadoop2.jar;E:\mavenrepository\commons-codec\commons-codec\1.7\commons-codec-1.7.jar;E:\mavenrepository\commons-io\commons-io\2.4\commons-io-2.4.jar;E:\mavenrepository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;E:\mavenrepository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;E:\mavenrepository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;E:\mavenrepository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;E:\mavenrepository\io\netty\netty\3.6.6.Final\netty-3.6.6.Final.jar;E:\mavenrepository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;E:\mavenrepository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;E:\mavenrepository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;E:\mavenrepository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;E:\mavenrepository\org\codehaus\jackson\jackson-mapper-asl\1.8.8\jackson-mapper-asl-1.8.8.jar;E:\mavenrepository\org\apache\hadoop\hadoop-common\2.2.0\hadoop-common-2.2.0.jar;E:\mavenrepository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;E:\mavenrepository\commons-net\commons-net\3.1\commons-net-3.1.jar;E:\mavenrepository\commons-el\commons-el\1.0\commons-el-1.0.jar;E:\mavenrepository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;E:\mavenrepository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;E:\mavenrepository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;E:\mavenrepository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;E:\mavenrepository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;E:\mavenrepository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;E:\mavenrepository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;E:\mavenrepository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;E:\mavenrepository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;E:\mavenrepository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;E:\mavenrepository\org\tukaani\xz\1.0\xz-1.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-mapreduce-client-core\2.2.0\hadoop-mapreduce-client-core-2.2.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;E:\mavenrepository\com\google\inject\guice\3.0\guice-3.0.jar;E:\mavenrepository\javax\inject\javax.inject\1\javax.inject-1.jar;E:\mavenrepository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;E:\mavenrepository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;E:\mavenrepository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-annotations\2.2.0\hadoop-annotations-2.2.0.jar;E:\mavenrepository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;E:\mavenrepository\org\apache\hbase\hbase-server\0.98.4-hadoop2\hbase-server-0.98.4-hadoop2.jar;E:\mavenrepository\org\apache\hbase\hbase-prefix-tree\0.98.4-hadoop2\hbase-prefix-tree-0.98.4-hadoop2.jar;E:\mavenrepository\org\apache\hbase\hbase-common\0.98.4-hadoop2\hbase-common-0.98.4-hadoop2-tests.jar;E:\mavenrepository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;E:\mavenrepository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;E:\mavenrepository\org\apache\hbase\hbase-hadoop2-compat\0.98.4-hadoop2\hbase-hadoop2-compat-0.98.4-hadoop2.jar;E:\mavenrepository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;E:\mavenrepository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;E:\mavenrepository\com\github\stephenc\high-scale-lib\high-scale-lib\1.1.1\high-scale-lib-1.1.1.jar;E:\mavenrepository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;E:\mavenrepository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;E:\mavenrepository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;E:\mavenrepository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;E:\mavenrepository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;E:\mavenrepository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;E:\mavenrepository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;E:\mavenrepository\org\codehaus\jackson\jackson-core-asl\1.8.8\jackson-core-asl-1.8.8.jar;E:\mavenrepository\org\codehaus\jackson\jackson-jaxrs\1.8.8\jackson-jaxrs-1.8.8.jar;E:\mavenrepository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;E:\mavenrepository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;E:\mavenrepository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;E:\mavenrepository\com\sun\jersey\jersey-core\1.8\jersey-core-1.8.jar;E:\mavenrepository\com\sun\jersey\jersey-json\1.8\jersey-json-1.8.jar;E:\mavenrepository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;E:\mavenrepository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;E:\mavenrepository\org\codehaus\jackson\jackson-xc\1.7.1\jackson-xc-1.7.1.jar;E:\mavenrepository\com\sun\jersey\jersey-server\1.8\jersey-server-1.8.jar;E:\mavenrepository\asm\asm\3.1\asm-3.1.jar;E:\mavenrepository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;E:\mavenrepository\javax\activation\activation\1.1\activation-1.1.jar;E:\mavenrepository\org\apache\hadoop\hadoop-hdfs\2.2.0\hadoop-hdfs-2.2.0.jar;E:\mavenrepository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;E:\mavenrepository\org\apache\hbase\hbase-hadoop-compat\0.98.4-hadoop2\hbase-hadoop-compat-0.98.4-hadoop2.jar;E:\mavenrepository\org\apache\hadoop\hadoop-client\2.4.0\hadoop-client-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-mapreduce-client-app\2.4.0\hadoop-mapreduce-client-app-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-mapreduce-client-common\2.4.0\hadoop-mapreduce-client-common-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-yarn-client\2.4.0\hadoop-yarn-client-2.4.0.jar;E:\mavenrepository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;E:\mavenrepository\org\apache\hadoop\hadoop-yarn-server-common\2.4.0\hadoop-yarn-server-common-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.4.0\hadoop-mapreduce-client-shuffle-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-yarn-api\2.4.0\hadoop-yarn-api-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.4.0\hadoop-mapreduce-client-jobclient-2.4.0.jar;C:\Program Files\Java\jdk1.8.0_60\lib\tools.jar
2015-12-17 14:47:47  [ main:1711 ] - [ INFO ]  Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_60\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jre1.8.0_66/bin/server;C:/Program Files/Java/jre1.8.0_66/bin;C:/Program Files/Java/jre1.8.0_66/lib/amd64;C:\ProgramData\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Java\jdk1.8.0_60\bin;D:\developtools\maven\apache-maven-3.2.3-bin\apache-maven-3.2.3\bin;D:\Program Files (x86)\Git\cmd;D:\snapshot;D:\Program Files\TortoiseSVN\bin;D:\developtools\apache-ant-1.9.4\bin;D:\Program Files (x86)\scala\bin;C:\Program Files (x86)\scala\bin;D:\Program Files (x86)\OpenVPN\bin;D:\developtools\eclipse64\eclipse;;.
2015-12-17 14:47:47  [ main:1711 ] - [ INFO ]  Client environment:java.io.tmpdir=C:\Users\ADMINI~1.K5Y\AppData\Local\Temp\
2015-12-17 14:47:47  [ main:1711 ] - [ INFO ]  Client environment:java.compiler=<NA>
2015-12-17 14:47:47  [ main:1711 ] - [ INFO ]  Client environment:os.name=Windows 7
2015-12-17 14:47:47  [ main:1711 ] - [ INFO ]  Client environment:os.arch=amd64
2015-12-17 14:47:47  [ main:1711 ] - [ INFO ]  Client environment:os.version=6.1
2015-12-17 14:47:47  [ main:1711 ] - [ INFO ]  Client environment:user.name=Administrator
2015-12-17 14:47:47  [ main:1712 ] - [ INFO ]  Client environment:user.home=C:\Users\Administrator.K5YUPM1XIRO9YVM
2015-12-17 14:47:47  [ main:1712 ] - [ INFO ]  Client environment:user.dir=E:\adunit\hadoop-tool
2015-12-17 14:47:47  [ main:1712 ] - [ INFO ]  Initiating client connection, connectString=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181 sessionTimeout=30000 watcher=hconnection-0x5383967b, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure
2015-12-17 14:47:47  [ main:1733 ] - [ DEBUG ]  zookeeper.disableAutoWatchReset is false
2015-12-17 14:47:47  [ main:2054 ] - [ INFO ]  Process identifier=hconnection-0x5383967b connecting to ZooKeeper ensemble=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181
2015-12-17 14:47:47  [ main-SendThread(storm14669:2181):2083 ] - [ INFO ]  Opening socket connection to server storm14669/192.168.146.69:2181. Will not attempt to authenticate using SASL (unknown error)
2015-12-17 14:47:47  [ main-SendThread(storm14669:2181):2090 ] - [ INFO ]  Socket connection established to storm14669/192.168.146.69:2181, initiating session
2015-12-17 14:47:47  [ main-SendThread(storm14669:2181):2092 ] - [ DEBUG ]  Session establishment request sent on storm14669/192.168.146.69:2181
2015-12-17 14:47:47  [ main-SendThread(storm14669:2181):2357 ] - [ INFO ]  Session establishment complete on server storm14669/192.168.146.69:2181, sessionid = 0x951565686380873, negotiated timeout = 30000
2015-12-17 14:47:47  [ main-EventThread:2359 ] - [ DEBUG ]  hconnection-0x5383967b, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2015-12-17 14:47:47  [ main-EventThread:2377 ] - [ DEBUG ]  hconnection-0x5383967b-0x951565686380873 connected
2015-12-17 14:47:47  [ main-SendThread(storm14669:2181):2396 ] - [ DEBUG ]  Reading reply sessionid:0x951565686380873, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,438132712288,0  request:: '/hbase-unsecure/hbaseid,F  response:: s{154655491313,438112239238,1432008035942,1449675376357,3,0,0,0,67,0,154655491313} 
2015-12-17 14:47:47  [ main-SendThread(storm14669:2181):2404 ] - [ DEBUG ]  Reading reply sessionid:0x951565686380873, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,438132712288,0  request:: '/hbase-unsecure/hbaseid,F  response:: #ffffffff000146d61737465723a36303030304fffffffef1ffffffffdffffff8b62553d50425546a2439666666343534382d643935652d343637352d626635652d623035626335363434353537,s{154655491313,438112239238,1432008035942,1449675376357,3,0,0,0,67,0,154655491313} 
2015-12-17 14:47:48  [ main:3046 ] - [ DEBUG ]  Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@13acb0d1, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2015-12-17 14:47:48  [ main-SendThread(storm14669:2181):3135 ] - [ DEBUG ]  Reading reply sessionid:0x951565686380873, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,438132712311,0  request:: '/hbase-unsecure/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffff8dffffffebffffffb3516fffffffd2ffffffb0650425546a19ac6861646f6f7031343631393010fffffff4ffffffd4318ffffffb1ffffffa9ffffff8bffffffbbffffff982a100,s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 14:47:48  [ main-SendThread(storm14669:2181):3149 ] - [ DEBUG ]  Reading reply sessionid:0x951565686380873, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,438132712311,0  request:: '/hbase-unsecure/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffff8dffffffebffffffb3516fffffffd2ffffffb0650425546a19ac6861646f6f7031343631393010fffffff4ffffffd4318ffffffb1ffffffa9ffffff8bffffffbbffffff982a100,s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 14:47:48  [ main:3399 ] - [ DEBUG ]  Use SIMPLE authentication for service ClientService, sasl=false
2015-12-17 14:47:48  [ main:3425 ] - [ DEBUG ]  Connecting to hadoop146190/192.168.146.190:60020
2015-12-17 14:47:48  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:3447 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: starting, connections 1
2015-12-17 14:47:48  [ main:3470 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 0 method_name: "Get" request_param: true
2015-12-17 14:47:49  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:3700 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 0, totalSize: 484 bytes
2015-12-17 14:47:49  [ main-SendThread(storm14669:2181):3786 ] - [ DEBUG ]  Reading reply sessionid:0x951565686380873, packet:: clientPath:null serverPath:null finished:false header:: 5,4  replyHeader:: 5,438132712330,0  request:: '/hbase-unsecure/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffff8dffffffebffffffb3516fffffffd2ffffffb0650425546a19ac6861646f6f7031343631393010fffffff4ffffffd4318ffffffb1ffffffa9ffffff8bffffffbbffffff982a100,s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 14:47:49  [ main:3797 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 1 method_name: "Scan" request_param: true priority: 100
2015-12-17 14:47:49  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:3990 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 1 cell_block_meta { length: 3430 }, totalSize: 3465 bytes
2015-12-17 14:47:49  [ main:4016 ] - [ DEBUG ]  Finished with small scan at {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2015-12-17 14:47:49  [ main:4062 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 2 method_name: "Scan" request_param: true
2015-12-17 14:47:49  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:4068 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 2, totalSize: 20 bytes
2015-12-17 14:47:49  [ main:4071 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 3 method_name: "Scan" request_param: true
2015-12-17 14:47:49  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:4092 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 3 cell_block_meta { length: 136453 }, totalSize: 136680 bytes
2015-12-17 14:47:49  [ main:4354 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 4 method_name: "Scan" request_param: true
2015-12-17 14:47:49  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:4374 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 4 cell_block_meta { length: 136579 }, totalSize: 136806 bytes
2015-12-17 14:47:50  [ main:4610 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 5 method_name: "Scan" request_param: true
2015-12-17 14:47:50  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:4634 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 5 cell_block_meta { length: 136550 }, totalSize: 136777 bytes
2015-12-17 14:47:50  [ main:4849 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 6 method_name: "Scan" request_param: true
2015-12-17 14:47:50  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:4878 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 6 cell_block_meta { length: 136570 }, totalSize: 136797 bytes
2015-12-17 14:47:50  [ main:5085 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 7 method_name: "Scan" request_param: true
2015-12-17 14:47:50  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:5128 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 7 cell_block_meta { length: 136565 }, totalSize: 136792 bytes
2015-12-17 14:47:50  [ main:5378 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 8 method_name: "Scan" request_param: true
2015-12-17 14:47:50  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:5400 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 8 cell_block_meta { length: 136563 }, totalSize: 136790 bytes
2015-12-17 14:47:51  [ main:5628 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 9 method_name: "Scan" request_param: true
2015-12-17 14:47:51  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:5661 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 9 cell_block_meta { length: 136579 }, totalSize: 136806 bytes
2015-12-17 14:47:51  [ main:5860 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 10 method_name: "Scan" request_param: true
2015-12-17 14:47:51  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:5910 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 10 cell_block_meta { length: 136568 }, totalSize: 136795 bytes
2015-12-17 14:47:51  [ main:6141 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 11 method_name: "Scan" request_param: true
2015-12-17 14:47:51  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:6160 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 11 cell_block_meta { length: 136567 }, totalSize: 136794 bytes
2015-12-17 14:47:51  [ main:6356 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 12 method_name: "Scan" request_param: true
2015-12-17 14:47:51  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:6403 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 12 cell_block_meta { length: 136572 }, totalSize: 136799 bytes
2015-12-17 14:47:51  [ main:6595 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 13 method_name: "Scan" request_param: true
2015-12-17 14:47:52  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:6646 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 13 cell_block_meta { length: 136565 }, totalSize: 136792 bytes
2015-12-17 14:47:57  [ main:0 ] - [ DEBUG ]  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, about=, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
2015-12-17 14:47:57  [ main:14 ] - [ DEBUG ]  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, about=, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
2015-12-17 14:47:57  [ main:16 ] - [ DEBUG ]  UgiMetrics, User and group related metrics
2015-12-17 14:47:58  [ main:140 ] - [ DEBUG ]  Kerberos krb5 configuration not found, setting default realm to empty
2015-12-17 14:47:58  [ main:143 ] - [ DEBUG ]   Creating new Groups object
2015-12-17 14:47:58  [ main:145 ] - [ DEBUG ]  Trying to load the custom-built native-hadoop library...
2015-12-17 14:47:58  [ main:147 ] - [ DEBUG ]  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-12-17 14:47:58  [ main:147 ] - [ DEBUG ]  java.library.path=C:\Program Files\Java\jdk1.8.0_60\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jre1.8.0_66/bin/server;C:/Program Files/Java/jre1.8.0_66/bin;C:/Program Files/Java/jre1.8.0_66/lib/amd64;C:\ProgramData\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Java\jdk1.8.0_60\bin;D:\developtools\maven\apache-maven-3.2.3-bin\apache-maven-3.2.3\bin;D:\Program Files (x86)\Git\cmd;D:\snapshot;D:\Program Files\TortoiseSVN\bin;D:\developtools\apache-ant-1.9.4\bin;D:\Program Files (x86)\scala\bin;C:\Program Files (x86)\scala\bin;D:\Program Files (x86)\OpenVPN\bin;D:\developtools\eclipse64\eclipse;;.
2015-12-17 14:47:58  [ main:147 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-12-17 14:47:58  [ main:147 ] - [ DEBUG ]  Falling back to shell based
2015-12-17 14:47:58  [ main:148 ] - [ DEBUG ]  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-12-17 14:47:58  [ main:148 ] - [ DEBUG ]  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
2015-12-17 14:47:58  [ main:154 ] - [ DEBUG ]  hadoop login
2015-12-17 14:47:58  [ main:155 ] - [ DEBUG ]  hadoop login commit
2015-12-17 14:47:58  [ main:161 ] - [ DEBUG ]  using local user:NTUserPrincipal: Administrator
2015-12-17 14:47:58  [ main:163 ] - [ DEBUG ]  UGI loginUser:Administrator (auth:SIMPLE)
2015-12-17 14:47:58  [ main:362 ] - [ DEBUG ]  Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:225)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:250)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.conf.Configuration.getStrings(Configuration.java:1514)
	at org.apache.hadoop.hbase.zookeeper.ZKConfig.makeZKProps(ZKConfig.java:113)
	at org.apache.hadoop.hbase.zookeeper.ZKConfig.getZKQuorumServersString(ZKConfig.java:265)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:159)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:134)
	at org.apache.hadoop.hbase.client.ZooKeeperKeepAliveConnection.<init>(ZooKeeperKeepAliveConnection.java:43)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getKeepAliveZooKeeperWatcher(HConnectionManager.java:1769)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:82)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.retrieveClusterId(HConnectionManager.java:858)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.<init>(HConnectionManager.java:663)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:415)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:394)
	at org.apache.hadoop.hbase.client.HConnectionManager.getConnection(HConnectionManager.java:275)
	at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:197)
	at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:159)
	at com.ipinyou.tool.hbase.HBaseUtils.getFilterDate(HBaseUtils.java:134)
	at com.ipinyou.tool.hbase.HBaseUtils.main(HBaseUtils.java:170)
2015-12-17 14:47:58  [ main:364 ] - [ ERROR ]  Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:278)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:300)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:293)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.conf.Configuration.getStrings(Configuration.java:1514)
	at org.apache.hadoop.hbase.zookeeper.ZKConfig.makeZKProps(ZKConfig.java:113)
	at org.apache.hadoop.hbase.zookeeper.ZKConfig.getZKQuorumServersString(ZKConfig.java:265)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:159)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:134)
	at org.apache.hadoop.hbase.client.ZooKeeperKeepAliveConnection.<init>(ZooKeeperKeepAliveConnection.java:43)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getKeepAliveZooKeeperWatcher(HConnectionManager.java:1769)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:82)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.retrieveClusterId(HConnectionManager.java:858)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.<init>(HConnectionManager.java:663)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:415)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:394)
	at org.apache.hadoop.hbase.client.HConnectionManager.getConnection(HConnectionManager.java:275)
	at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:197)
	at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:159)
	at com.ipinyou.tool.hbase.HBaseUtils.getFilterDate(HBaseUtils.java:134)
	at com.ipinyou.tool.hbase.HBaseUtils.main(HBaseUtils.java:170)
2015-12-17 14:47:59  [ main:1528 ] - [ INFO ]  Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2015-12-17 14:47:59  [ main:1528 ] - [ INFO ]  Client environment:host.name=10.1.2.39
2015-12-17 14:47:59  [ main:1529 ] - [ INFO ]  Client environment:java.version=1.8.0_60
2015-12-17 14:47:59  [ main:1529 ] - [ INFO ]  Client environment:java.vendor=Oracle Corporation
2015-12-17 14:47:59  [ main:1529 ] - [ INFO ]  Client environment:java.home=C:\Program Files\Java\jdk1.8.0_60\jre
2015-12-17 14:47:59  [ main:1529 ] - [ INFO ]  Client environment:java.class.path=E:\adunit\hadoop-tool\target\classes;E:\mavenrepository\log4j\log4j\1.2.14\log4j-1.2.14.jar;E:\mavenrepository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;E:\mavenrepository\org\apache\hbase\hbase-client\0.98.4-hadoop2\hbase-client-0.98.4-hadoop2.jar;E:\mavenrepository\org\apache\hbase\hbase-common\0.98.4-hadoop2\hbase-common-0.98.4-hadoop2.jar;E:\mavenrepository\org\apache\hbase\hbase-protocol\0.98.4-hadoop2\hbase-protocol-0.98.4-hadoop2.jar;E:\mavenrepository\commons-codec\commons-codec\1.7\commons-codec-1.7.jar;E:\mavenrepository\commons-io\commons-io\2.4\commons-io-2.4.jar;E:\mavenrepository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;E:\mavenrepository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;E:\mavenrepository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;E:\mavenrepository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;E:\mavenrepository\io\netty\netty\3.6.6.Final\netty-3.6.6.Final.jar;E:\mavenrepository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;E:\mavenrepository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;E:\mavenrepository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;E:\mavenrepository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;E:\mavenrepository\org\codehaus\jackson\jackson-mapper-asl\1.8.8\jackson-mapper-asl-1.8.8.jar;E:\mavenrepository\org\apache\hadoop\hadoop-common\2.2.0\hadoop-common-2.2.0.jar;E:\mavenrepository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;E:\mavenrepository\commons-net\commons-net\3.1\commons-net-3.1.jar;E:\mavenrepository\commons-el\commons-el\1.0\commons-el-1.0.jar;E:\mavenrepository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;E:\mavenrepository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;E:\mavenrepository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;E:\mavenrepository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;E:\mavenrepository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;E:\mavenrepository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;E:\mavenrepository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;E:\mavenrepository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;E:\mavenrepository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;E:\mavenrepository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;E:\mavenrepository\org\tukaani\xz\1.0\xz-1.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-mapreduce-client-core\2.2.0\hadoop-mapreduce-client-core-2.2.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;E:\mavenrepository\com\google\inject\guice\3.0\guice-3.0.jar;E:\mavenrepository\javax\inject\javax.inject\1\javax.inject-1.jar;E:\mavenrepository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;E:\mavenrepository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;E:\mavenrepository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-annotations\2.2.0\hadoop-annotations-2.2.0.jar;E:\mavenrepository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;E:\mavenrepository\org\apache\hbase\hbase-server\0.98.4-hadoop2\hbase-server-0.98.4-hadoop2.jar;E:\mavenrepository\org\apache\hbase\hbase-prefix-tree\0.98.4-hadoop2\hbase-prefix-tree-0.98.4-hadoop2.jar;E:\mavenrepository\org\apache\hbase\hbase-common\0.98.4-hadoop2\hbase-common-0.98.4-hadoop2-tests.jar;E:\mavenrepository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;E:\mavenrepository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;E:\mavenrepository\org\apache\hbase\hbase-hadoop2-compat\0.98.4-hadoop2\hbase-hadoop2-compat-0.98.4-hadoop2.jar;E:\mavenrepository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;E:\mavenrepository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;E:\mavenrepository\com\github\stephenc\high-scale-lib\high-scale-lib\1.1.1\high-scale-lib-1.1.1.jar;E:\mavenrepository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;E:\mavenrepository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;E:\mavenrepository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;E:\mavenrepository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;E:\mavenrepository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;E:\mavenrepository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;E:\mavenrepository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;E:\mavenrepository\org\codehaus\jackson\jackson-core-asl\1.8.8\jackson-core-asl-1.8.8.jar;E:\mavenrepository\org\codehaus\jackson\jackson-jaxrs\1.8.8\jackson-jaxrs-1.8.8.jar;E:\mavenrepository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;E:\mavenrepository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;E:\mavenrepository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;E:\mavenrepository\com\sun\jersey\jersey-core\1.8\jersey-core-1.8.jar;E:\mavenrepository\com\sun\jersey\jersey-json\1.8\jersey-json-1.8.jar;E:\mavenrepository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;E:\mavenrepository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;E:\mavenrepository\org\codehaus\jackson\jackson-xc\1.7.1\jackson-xc-1.7.1.jar;E:\mavenrepository\com\sun\jersey\jersey-server\1.8\jersey-server-1.8.jar;E:\mavenrepository\asm\asm\3.1\asm-3.1.jar;E:\mavenrepository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;E:\mavenrepository\javax\activation\activation\1.1\activation-1.1.jar;E:\mavenrepository\org\apache\hadoop\hadoop-hdfs\2.2.0\hadoop-hdfs-2.2.0.jar;E:\mavenrepository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;E:\mavenrepository\org\apache\hbase\hbase-hadoop-compat\0.98.4-hadoop2\hbase-hadoop-compat-0.98.4-hadoop2.jar;E:\mavenrepository\org\apache\hadoop\hadoop-client\2.4.0\hadoop-client-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-mapreduce-client-app\2.4.0\hadoop-mapreduce-client-app-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-mapreduce-client-common\2.4.0\hadoop-mapreduce-client-common-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-yarn-client\2.4.0\hadoop-yarn-client-2.4.0.jar;E:\mavenrepository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;E:\mavenrepository\org\apache\hadoop\hadoop-yarn-server-common\2.4.0\hadoop-yarn-server-common-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.4.0\hadoop-mapreduce-client-shuffle-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-yarn-api\2.4.0\hadoop-yarn-api-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.4.0\hadoop-mapreduce-client-jobclient-2.4.0.jar;C:\Program Files\Java\jdk1.8.0_60\lib\tools.jar
2015-12-17 14:47:59  [ main:1529 ] - [ INFO ]  Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_60\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jre1.8.0_66/bin/server;C:/Program Files/Java/jre1.8.0_66/bin;C:/Program Files/Java/jre1.8.0_66/lib/amd64;C:\ProgramData\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Java\jdk1.8.0_60\bin;D:\developtools\maven\apache-maven-3.2.3-bin\apache-maven-3.2.3\bin;D:\Program Files (x86)\Git\cmd;D:\snapshot;D:\Program Files\TortoiseSVN\bin;D:\developtools\apache-ant-1.9.4\bin;D:\Program Files (x86)\scala\bin;C:\Program Files (x86)\scala\bin;D:\Program Files (x86)\OpenVPN\bin;D:\developtools\eclipse64\eclipse;;.
2015-12-17 14:47:59  [ main:1529 ] - [ INFO ]  Client environment:java.io.tmpdir=C:\Users\ADMINI~1.K5Y\AppData\Local\Temp\
2015-12-17 14:47:59  [ main:1529 ] - [ INFO ]  Client environment:java.compiler=<NA>
2015-12-17 14:47:59  [ main:1529 ] - [ INFO ]  Client environment:os.name=Windows 7
2015-12-17 14:47:59  [ main:1530 ] - [ INFO ]  Client environment:os.arch=amd64
2015-12-17 14:47:59  [ main:1530 ] - [ INFO ]  Client environment:os.version=6.1
2015-12-17 14:47:59  [ main:1530 ] - [ INFO ]  Client environment:user.name=Administrator
2015-12-17 14:47:59  [ main:1530 ] - [ INFO ]  Client environment:user.home=C:\Users\Administrator.K5YUPM1XIRO9YVM
2015-12-17 14:47:59  [ main:1530 ] - [ INFO ]  Client environment:user.dir=E:\adunit\hadoop-tool
2015-12-17 14:47:59  [ main:1531 ] - [ INFO ]  Initiating client connection, connectString=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181 sessionTimeout=30000 watcher=hconnection-0x5383967b, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure
2015-12-17 14:47:59  [ main:1535 ] - [ DEBUG ]  zookeeper.disableAutoWatchReset is false
2015-12-17 14:47:59  [ main:1623 ] - [ INFO ]  Process identifier=hconnection-0x5383967b connecting to ZooKeeper ensemble=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181
2015-12-17 14:47:59  [ main-SendThread(hadoop146066.ysc.com:2181):1641 ] - [ INFO ]  Opening socket connection to server hadoop146066.ysc.com/192.168.146.66:2181. Will not attempt to authenticate using SASL (unknown error)
2015-12-17 14:47:59  [ main-SendThread(hadoop146066.ysc.com:2181):1649 ] - [ INFO ]  Socket connection established to hadoop146066.ysc.com/192.168.146.66:2181, initiating session
2015-12-17 14:47:59  [ main-SendThread(hadoop146066.ysc.com:2181):1650 ] - [ DEBUG ]  Session establishment request sent on hadoop146066.ysc.com/192.168.146.66:2181
2015-12-17 14:47:59  [ main-SendThread(hadoop146066.ysc.com:2181):1901 ] - [ INFO ]  Session establishment complete on server hadoop146066.ysc.com/192.168.146.66:2181, sessionid = 0x1516dcdc7b7060c, negotiated timeout = 30000
2015-12-17 14:47:59  [ main-EventThread:1905 ] - [ DEBUG ]  hconnection-0x5383967b, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2015-12-17 14:47:59  [ main-EventThread:1908 ] - [ DEBUG ]  hconnection-0x5383967b-0x1516dcdc7b7060c connected
2015-12-17 14:47:59  [ main-SendThread(hadoop146066.ysc.com:2181):1917 ] - [ DEBUG ]  Reading reply sessionid:0x1516dcdc7b7060c, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,438132712657,0  request:: '/hbase-unsecure/hbaseid,F  response:: s{154655491313,438112239238,1432008035942,1449675376357,3,0,0,0,67,0,154655491313} 
2015-12-17 14:47:59  [ main-SendThread(hadoop146066.ysc.com:2181):1926 ] - [ DEBUG ]  Reading reply sessionid:0x1516dcdc7b7060c, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,438132712657,0  request:: '/hbase-unsecure/hbaseid,F  response:: #ffffffff000146d61737465723a36303030304fffffffef1ffffffffdffffff8b62553d50425546a2439666666343534382d643935652d343637352d626635652d623035626335363434353537,s{154655491313,438112239238,1432008035942,1449675376357,3,0,0,0,67,0,154655491313} 
2015-12-17 14:48:00  [ main:2150 ] - [ DEBUG ]  Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@13acb0d1, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2015-12-17 14:48:00  [ main-SendThread(hadoop146066.ysc.com:2181):2181 ] - [ DEBUG ]  Reading reply sessionid:0x1516dcdc7b7060c, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,438132712666,0  request:: '/hbase-unsecure/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffff8dffffffebffffffb3516fffffffd2ffffffb0650425546a19ac6861646f6f7031343631393010fffffff4ffffffd4318ffffffb1ffffffa9ffffff8bffffffbbffffff982a100,s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 14:48:00  [ main-SendThread(hadoop146066.ysc.com:2181):2193 ] - [ DEBUG ]  Reading reply sessionid:0x1516dcdc7b7060c, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,438132712666,0  request:: '/hbase-unsecure/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffff8dffffffebffffffb3516fffffffd2ffffffb0650425546a19ac6861646f6f7031343631393010fffffff4ffffffd4318ffffffb1ffffffa9ffffff8bffffffbbffffff982a100,s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 14:48:00  [ main:2318 ] - [ DEBUG ]  Use SIMPLE authentication for service ClientService, sasl=false
2015-12-17 14:48:00  [ main:2323 ] - [ DEBUG ]  Connecting to hadoop146190/192.168.146.190:60020
2015-12-17 14:48:00  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:2332 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: starting, connections 1
2015-12-17 14:48:00  [ main:2343 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 0 method_name: "Get" request_param: true
2015-12-17 14:48:00  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:2404 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 0, totalSize: 484 bytes
2015-12-17 14:48:00  [ main-SendThread(hadoop146066.ysc.com:2181):2612 ] - [ DEBUG ]  Reading reply sessionid:0x1516dcdc7b7060c, packet:: clientPath:null serverPath:null finished:false header:: 5,4  replyHeader:: 5,438132712673,0  request:: '/hbase-unsecure/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffff8dffffffebffffffb3516fffffffd2ffffffb0650425546a19ac6861646f6f7031343631393010fffffff4ffffffd4318ffffffb1ffffffa9ffffff8bffffffbbffffff982a100,s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 14:48:00  [ main:2623 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 1 method_name: "Scan" request_param: true priority: 100
2015-12-17 14:48:00  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:2823 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 1 cell_block_meta { length: 3430 }, totalSize: 3465 bytes
2015-12-17 14:48:00  [ main:2827 ] - [ DEBUG ]  Finished with small scan at {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2015-12-17 14:48:00  [ main:2851 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 2 method_name: "Scan" request_param: true
2015-12-17 14:48:00  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:2867 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 2, totalSize: 20 bytes
2015-12-17 14:48:00  [ main:2868 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 3 method_name: "Scan" request_param: true
2015-12-17 14:48:00  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:2887 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 3 cell_block_meta { length: 136453 }, totalSize: 136680 bytes
2015-12-17 14:48:01  [ main:3125 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 4 method_name: "Scan" request_param: true
2015-12-17 14:48:01  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:3145 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 4 cell_block_meta { length: 136579 }, totalSize: 136806 bytes
2015-12-17 14:48:01  [ main:3371 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 5 method_name: "Scan" request_param: true
2015-12-17 14:48:01  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:3410 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 5 cell_block_meta { length: 136550 }, totalSize: 136777 bytes
2015-12-17 14:48:01  [ main:3621 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 6 method_name: "Scan" request_param: true
2015-12-17 15:10:12  [ main:0 ] - [ DEBUG ]  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
2015-12-17 15:10:12  [ main:15 ] - [ DEBUG ]  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
2015-12-17 15:10:12  [ main:16 ] - [ DEBUG ]  UgiMetrics, User and group related metrics
2015-12-17 15:10:12  [ main:153 ] - [ DEBUG ]  Kerberos krb5 configuration not found, setting default realm to empty
2015-12-17 15:10:12  [ main:155 ] - [ DEBUG ]   Creating new Groups object
2015-12-17 15:10:12  [ main:158 ] - [ DEBUG ]  Trying to load the custom-built native-hadoop library...
2015-12-17 15:10:12  [ main:160 ] - [ DEBUG ]  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-12-17 15:10:12  [ main:160 ] - [ DEBUG ]  java.library.path=C:\Program Files\Java\jdk1.8.0_60\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jre1.8.0_66/bin/server;C:/Program Files/Java/jre1.8.0_66/bin;C:/Program Files/Java/jre1.8.0_66/lib/amd64;C:\ProgramData\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Java\jdk1.8.0_60\bin;D:\developtools\maven\apache-maven-3.2.3-bin\apache-maven-3.2.3\bin;D:\Program Files (x86)\Git\cmd;D:\snapshot;D:\Program Files\TortoiseSVN\bin;D:\developtools\apache-ant-1.9.4\bin;D:\Program Files (x86)\scala\bin;C:\Program Files (x86)\scala\bin;D:\Program Files (x86)\OpenVPN\bin;D:\developtools\eclipse64\eclipse;;.
2015-12-17 15:10:12  [ main:160 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-12-17 15:10:12  [ main:160 ] - [ DEBUG ]  Falling back to shell based
2015-12-17 15:10:12  [ main:161 ] - [ DEBUG ]  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-12-17 15:10:12  [ main:161 ] - [ DEBUG ]  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
2015-12-17 15:10:12  [ main:170 ] - [ DEBUG ]  hadoop login
2015-12-17 15:10:12  [ main:171 ] - [ DEBUG ]  hadoop login commit
2015-12-17 15:10:12  [ main:177 ] - [ DEBUG ]  using local user:NTUserPrincipal: Administrator
2015-12-17 15:10:12  [ main:178 ] - [ DEBUG ]  UGI loginUser:Administrator (auth:SIMPLE)
2015-12-17 15:10:12  [ main:378 ] - [ DEBUG ]  Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:225)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:250)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.conf.Configuration.getStrings(Configuration.java:1514)
	at org.apache.hadoop.hbase.zookeeper.ZKConfig.makeZKProps(ZKConfig.java:113)
	at org.apache.hadoop.hbase.zookeeper.ZKConfig.getZKQuorumServersString(ZKConfig.java:265)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:159)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:134)
	at org.apache.hadoop.hbase.client.ZooKeeperKeepAliveConnection.<init>(ZooKeeperKeepAliveConnection.java:43)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getKeepAliveZooKeeperWatcher(HConnectionManager.java:1769)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:82)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.retrieveClusterId(HConnectionManager.java:858)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.<init>(HConnectionManager.java:663)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:415)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:394)
	at org.apache.hadoop.hbase.client.HConnectionManager.getConnection(HConnectionManager.java:275)
	at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:197)
	at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:159)
	at com.ipinyou.tool.hbase.HBaseUtils.getFilterDate(HBaseUtils.java:134)
	at com.ipinyou.tool.hbase.HBaseUtils.main(HBaseUtils.java:170)
2015-12-17 15:10:12  [ main:379 ] - [ ERROR ]  Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:278)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:300)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:293)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.conf.Configuration.getStrings(Configuration.java:1514)
	at org.apache.hadoop.hbase.zookeeper.ZKConfig.makeZKProps(ZKConfig.java:113)
	at org.apache.hadoop.hbase.zookeeper.ZKConfig.getZKQuorumServersString(ZKConfig.java:265)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:159)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:134)
	at org.apache.hadoop.hbase.client.ZooKeeperKeepAliveConnection.<init>(ZooKeeperKeepAliveConnection.java:43)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getKeepAliveZooKeeperWatcher(HConnectionManager.java:1769)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:82)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.retrieveClusterId(HConnectionManager.java:858)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.<init>(HConnectionManager.java:663)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:415)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:394)
	at org.apache.hadoop.hbase.client.HConnectionManager.getConnection(HConnectionManager.java:275)
	at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:197)
	at org.apache.hadoop.hbase.client.HTable.<init>(HTable.java:159)
	at com.ipinyou.tool.hbase.HBaseUtils.getFilterDate(HBaseUtils.java:134)
	at com.ipinyou.tool.hbase.HBaseUtils.main(HBaseUtils.java:170)
2015-12-17 15:10:13  [ main:608 ] - [ INFO ]  Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2015-12-17 15:10:13  [ main:608 ] - [ INFO ]  Client environment:host.name=10.1.2.39
2015-12-17 15:10:13  [ main:608 ] - [ INFO ]  Client environment:java.version=1.8.0_60
2015-12-17 15:10:13  [ main:608 ] - [ INFO ]  Client environment:java.vendor=Oracle Corporation
2015-12-17 15:10:13  [ main:608 ] - [ INFO ]  Client environment:java.home=C:\Program Files\Java\jdk1.8.0_60\jre
2015-12-17 15:10:13  [ main:608 ] - [ INFO ]  Client environment:java.class.path=E:\adunit\hadoop-tool\target\classes;E:\mavenrepository\log4j\log4j\1.2.14\log4j-1.2.14.jar;E:\mavenrepository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;E:\mavenrepository\org\apache\hbase\hbase-client\0.98.4-hadoop2\hbase-client-0.98.4-hadoop2.jar;E:\mavenrepository\org\apache\hbase\hbase-common\0.98.4-hadoop2\hbase-common-0.98.4-hadoop2.jar;E:\mavenrepository\org\apache\hbase\hbase-protocol\0.98.4-hadoop2\hbase-protocol-0.98.4-hadoop2.jar;E:\mavenrepository\commons-codec\commons-codec\1.7\commons-codec-1.7.jar;E:\mavenrepository\commons-io\commons-io\2.4\commons-io-2.4.jar;E:\mavenrepository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;E:\mavenrepository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;E:\mavenrepository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;E:\mavenrepository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;E:\mavenrepository\io\netty\netty\3.6.6.Final\netty-3.6.6.Final.jar;E:\mavenrepository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;E:\mavenrepository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;E:\mavenrepository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;E:\mavenrepository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;E:\mavenrepository\org\codehaus\jackson\jackson-mapper-asl\1.8.8\jackson-mapper-asl-1.8.8.jar;E:\mavenrepository\org\apache\hadoop\hadoop-common\2.2.0\hadoop-common-2.2.0.jar;E:\mavenrepository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;E:\mavenrepository\commons-net\commons-net\3.1\commons-net-3.1.jar;E:\mavenrepository\commons-el\commons-el\1.0\commons-el-1.0.jar;E:\mavenrepository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;E:\mavenrepository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;E:\mavenrepository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;E:\mavenrepository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;E:\mavenrepository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;E:\mavenrepository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;E:\mavenrepository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;E:\mavenrepository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;E:\mavenrepository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;E:\mavenrepository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;E:\mavenrepository\org\tukaani\xz\1.0\xz-1.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-mapreduce-client-core\2.2.0\hadoop-mapreduce-client-core-2.2.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;E:\mavenrepository\com\google\inject\guice\3.0\guice-3.0.jar;E:\mavenrepository\javax\inject\javax.inject\1\javax.inject-1.jar;E:\mavenrepository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;E:\mavenrepository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;E:\mavenrepository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-annotations\2.2.0\hadoop-annotations-2.2.0.jar;E:\mavenrepository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;E:\mavenrepository\org\apache\hbase\hbase-server\0.98.4-hadoop2\hbase-server-0.98.4-hadoop2.jar;E:\mavenrepository\org\apache\hbase\hbase-prefix-tree\0.98.4-hadoop2\hbase-prefix-tree-0.98.4-hadoop2.jar;E:\mavenrepository\org\apache\hbase\hbase-common\0.98.4-hadoop2\hbase-common-0.98.4-hadoop2-tests.jar;E:\mavenrepository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;E:\mavenrepository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;E:\mavenrepository\org\apache\hbase\hbase-hadoop2-compat\0.98.4-hadoop2\hbase-hadoop2-compat-0.98.4-hadoop2.jar;E:\mavenrepository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;E:\mavenrepository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;E:\mavenrepository\com\github\stephenc\high-scale-lib\high-scale-lib\1.1.1\high-scale-lib-1.1.1.jar;E:\mavenrepository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;E:\mavenrepository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;E:\mavenrepository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;E:\mavenrepository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;E:\mavenrepository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;E:\mavenrepository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;E:\mavenrepository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;E:\mavenrepository\org\codehaus\jackson\jackson-core-asl\1.8.8\jackson-core-asl-1.8.8.jar;E:\mavenrepository\org\codehaus\jackson\jackson-jaxrs\1.8.8\jackson-jaxrs-1.8.8.jar;E:\mavenrepository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;E:\mavenrepository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;E:\mavenrepository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;E:\mavenrepository\com\sun\jersey\jersey-core\1.8\jersey-core-1.8.jar;E:\mavenrepository\com\sun\jersey\jersey-json\1.8\jersey-json-1.8.jar;E:\mavenrepository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;E:\mavenrepository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;E:\mavenrepository\org\codehaus\jackson\jackson-xc\1.7.1\jackson-xc-1.7.1.jar;E:\mavenrepository\com\sun\jersey\jersey-server\1.8\jersey-server-1.8.jar;E:\mavenrepository\asm\asm\3.1\asm-3.1.jar;E:\mavenrepository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;E:\mavenrepository\javax\activation\activation\1.1\activation-1.1.jar;E:\mavenrepository\org\apache\hadoop\hadoop-hdfs\2.2.0\hadoop-hdfs-2.2.0.jar;E:\mavenrepository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;E:\mavenrepository\org\apache\hbase\hbase-hadoop-compat\0.98.4-hadoop2\hbase-hadoop-compat-0.98.4-hadoop2.jar;E:\mavenrepository\org\apache\hadoop\hadoop-client\2.4.0\hadoop-client-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-mapreduce-client-app\2.4.0\hadoop-mapreduce-client-app-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-mapreduce-client-common\2.4.0\hadoop-mapreduce-client-common-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-yarn-client\2.4.0\hadoop-yarn-client-2.4.0.jar;E:\mavenrepository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;E:\mavenrepository\org\apache\hadoop\hadoop-yarn-server-common\2.4.0\hadoop-yarn-server-common-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.4.0\hadoop-mapreduce-client-shuffle-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-yarn-api\2.4.0\hadoop-yarn-api-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.4.0\hadoop-mapreduce-client-jobclient-2.4.0.jar;C:\Program Files\Java\jdk1.8.0_60\lib\tools.jar
2015-12-17 15:10:13  [ main:609 ] - [ INFO ]  Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_60\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jre1.8.0_66/bin/server;C:/Program Files/Java/jre1.8.0_66/bin;C:/Program Files/Java/jre1.8.0_66/lib/amd64;C:\ProgramData\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Java\jdk1.8.0_60\bin;D:\developtools\maven\apache-maven-3.2.3-bin\apache-maven-3.2.3\bin;D:\Program Files (x86)\Git\cmd;D:\snapshot;D:\Program Files\TortoiseSVN\bin;D:\developtools\apache-ant-1.9.4\bin;D:\Program Files (x86)\scala\bin;C:\Program Files (x86)\scala\bin;D:\Program Files (x86)\OpenVPN\bin;D:\developtools\eclipse64\eclipse;;.
2015-12-17 15:10:13  [ main:609 ] - [ INFO ]  Client environment:java.io.tmpdir=C:\Users\ADMINI~1.K5Y\AppData\Local\Temp\
2015-12-17 15:10:13  [ main:609 ] - [ INFO ]  Client environment:java.compiler=<NA>
2015-12-17 15:10:13  [ main:609 ] - [ INFO ]  Client environment:os.name=Windows 7
2015-12-17 15:10:13  [ main:609 ] - [ INFO ]  Client environment:os.arch=amd64
2015-12-17 15:10:13  [ main:609 ] - [ INFO ]  Client environment:os.version=6.1
2015-12-17 15:10:13  [ main:609 ] - [ INFO ]  Client environment:user.name=Administrator
2015-12-17 15:10:13  [ main:609 ] - [ INFO ]  Client environment:user.home=C:\Users\Administrator.K5YUPM1XIRO9YVM
2015-12-17 15:10:13  [ main:611 ] - [ INFO ]  Client environment:user.dir=E:\adunit\hadoop-tool
2015-12-17 15:10:13  [ main:613 ] - [ INFO ]  Initiating client connection, connectString=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181 sessionTimeout=30000 watcher=hconnection-0x5383967b, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure
2015-12-17 15:10:13  [ main:627 ] - [ DEBUG ]  zookeeper.disableAutoWatchReset is false
2015-12-17 15:10:13  [ main:748 ] - [ INFO ]  Process identifier=hconnection-0x5383967b connecting to ZooKeeper ensemble=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181
2015-12-17 15:10:13  [ main-SendThread(storm14664:2181):763 ] - [ INFO ]  Opening socket connection to server storm14664/192.168.146.64:2181. Will not attempt to authenticate using SASL (unknown error)
2015-12-17 15:10:13  [ main-SendThread(storm14664:2181):768 ] - [ INFO ]  Socket connection established to storm14664/192.168.146.64:2181, initiating session
2015-12-17 15:10:13  [ main-SendThread(storm14664:2181):769 ] - [ DEBUG ]  Session establishment request sent on storm14664/192.168.146.64:2181
2015-12-17 15:10:13  [ main-SendThread(storm14664:2181):1017 ] - [ INFO ]  Session establishment complete on server storm14664/192.168.146.64:2181, sessionid = 0x5515656863d085c, negotiated timeout = 30000
2015-12-17 15:10:13  [ main-EventThread:1019 ] - [ DEBUG ]  hconnection-0x5383967b, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2015-12-17 15:10:13  [ main-EventThread:1021 ] - [ DEBUG ]  hconnection-0x5383967b-0x5515656863d085c connected
2015-12-17 15:10:13  [ main-SendThread(storm14664:2181):1029 ] - [ DEBUG ]  Reading reply sessionid:0x5515656863d085c, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,438132753145,0  request:: '/hbase-unsecure/hbaseid,F  response:: s{154655491313,438112239238,1432008035942,1449675376357,3,0,0,0,67,0,154655491313} 
2015-12-17 15:10:13  [ main-SendThread(storm14664:2181):1036 ] - [ DEBUG ]  Reading reply sessionid:0x5515656863d085c, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,438132753145,0  request:: '/hbase-unsecure/hbaseid,F  response:: #ffffffff000146d61737465723a36303030304fffffffef1ffffffffdffffff8b62553d50425546a2439666666343534382d643935652d343637352d626635652d623035626335363434353537,s{154655491313,438112239238,1432008035942,1449675376357,3,0,0,0,67,0,154655491313} 
2015-12-17 15:10:13  [ main:1279 ] - [ DEBUG ]  Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@13acb0d1, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2015-12-17 15:10:13  [ main-SendThread(storm14664:2181):1304 ] - [ DEBUG ]  Reading reply sessionid:0x5515656863d085c, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,438132753154,0  request:: '/hbase-unsecure/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffff8dffffffebffffffb3516fffffffd2ffffffb0650425546a19ac6861646f6f7031343631393010fffffff4ffffffd4318ffffffb1ffffffa9ffffff8bffffffbbffffff982a100,s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 15:10:13  [ main-SendThread(storm14664:2181):1317 ] - [ DEBUG ]  Reading reply sessionid:0x5515656863d085c, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,438132753155,0  request:: '/hbase-unsecure/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffff8dffffffebffffffb3516fffffffd2ffffffb0650425546a19ac6861646f6f7031343631393010fffffff4ffffffd4318ffffffb1ffffffa9ffffff8bffffffbbffffff982a100,s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 15:10:14  [ main:1439 ] - [ DEBUG ]  Use SIMPLE authentication for service ClientService, sasl=false
2015-12-17 15:10:14  [ main:1446 ] - [ DEBUG ]  Connecting to hadoop146190/192.168.146.190:60020
2015-12-17 15:10:14  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:1456 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: starting, connections 1
2015-12-17 15:10:14  [ main:1468 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 0 method_name: "Get" request_param: true
2015-12-17 15:10:14  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:1523 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 0, totalSize: 484 bytes
2015-12-17 15:10:14  [ main-SendThread(storm14664:2181):1557 ] - [ DEBUG ]  Reading reply sessionid:0x5515656863d085c, packet:: clientPath:null serverPath:null finished:false header:: 5,4  replyHeader:: 5,438132753163,0  request:: '/hbase-unsecure/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffff8dffffffebffffffb3516fffffffd2ffffffb0650425546a19ac6861646f6f7031343631393010fffffff4ffffffd4318ffffffb1ffffffa9ffffff8bffffffbbffffff982a100,s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 15:10:14  [ main:1567 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 1 method_name: "Scan" request_param: true priority: 100
2015-12-17 15:10:14  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:1755 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 1 cell_block_meta { length: 3430 }, totalSize: 3465 bytes
2015-12-17 15:10:14  [ main:1761 ] - [ DEBUG ]  Finished with small scan at {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2015-12-17 15:10:14  [ main:1789 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 2 method_name: "Scan" request_param: true
2015-12-17 15:10:14  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:1800 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 2, totalSize: 20 bytes
2015-12-17 15:10:14  [ main:1801 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 3 method_name: "Scan" request_param: true
2015-12-17 15:10:14  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:1821 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 3 cell_block_meta { length: 136453 }, totalSize: 136680 bytes
2015-12-17 15:10:14  [ main:2067 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 4 method_name: "Scan" request_param: true
2015-12-17 15:10:14  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:2086 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 4 cell_block_meta { length: 136579 }, totalSize: 136806 bytes
2015-12-17 15:10:14  [ main:2299 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 5 method_name: "Scan" request_param: true
2015-12-17 15:10:14  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:2343 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 5 cell_block_meta { length: 136550 }, totalSize: 136777 bytes
2015-12-17 15:10:15  [ main:2581 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 6 method_name: "Scan" request_param: true
2015-12-17 15:10:15  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:2603 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 6 cell_block_meta { length: 136570 }, totalSize: 136797 bytes
2015-12-17 15:10:15  [ main:2808 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 7 method_name: "Scan" request_param: true
2015-12-17 15:10:15  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:2859 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 7 cell_block_meta { length: 136565 }, totalSize: 136792 bytes
2015-12-17 15:10:15  [ main:3094 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 8 method_name: "Scan" request_param: true
2015-12-17 15:10:15  [ IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator:3113 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 8 cell_block_meta { length: 136563 }, totalSize: 136790 bytes
2015-12-17 15:10:15  [ main:3310 ] - [ DEBUG ]  IPC Client (898406901) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 9 method_name: "Scan" request_param: true
2015-12-17 16:44:51  [ main:0 ] - [ DEBUG ]  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
2015-12-17 16:44:51  [ main:13 ] - [ DEBUG ]  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
2015-12-17 16:44:51  [ main:14 ] - [ DEBUG ]  UgiMetrics, User and group related metrics
2015-12-17 16:44:51  [ main:136 ] - [ DEBUG ]  Kerberos krb5 configuration not found, setting default realm to empty
2015-12-17 16:44:51  [ main:139 ] - [ DEBUG ]   Creating new Groups object
2015-12-17 16:44:51  [ main:141 ] - [ DEBUG ]  Trying to load the custom-built native-hadoop library...
2015-12-17 16:44:51  [ main:143 ] - [ DEBUG ]  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-12-17 16:44:51  [ main:143 ] - [ DEBUG ]  java.library.path=C:\Program Files\Java\jdk1.8.0_60\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jre1.8.0_66/bin/server;C:/Program Files/Java/jre1.8.0_66/bin;C:/Program Files/Java/jre1.8.0_66/lib/amd64;C:\ProgramData\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Java\jdk1.8.0_60\bin;D:\developtools\maven\apache-maven-3.2.3-bin\apache-maven-3.2.3\bin;D:\Program Files (x86)\Git\cmd;D:\snapshot;D:\Program Files\TortoiseSVN\bin;D:\developtools\apache-ant-1.9.4\bin;D:\Program Files (x86)\scala\bin;C:\Program Files (x86)\scala\bin;D:\Program Files (x86)\OpenVPN\bin;D:\developtools\eclipse64\eclipse;;.
2015-12-17 16:44:51  [ main:143 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-12-17 16:44:51  [ main:144 ] - [ DEBUG ]  Falling back to shell based
2015-12-17 16:44:51  [ main:145 ] - [ DEBUG ]  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-12-17 16:44:51  [ main:145 ] - [ DEBUG ]  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
2015-12-17 16:44:51  [ main:150 ] - [ DEBUG ]  hadoop login
2015-12-17 16:44:51  [ main:151 ] - [ DEBUG ]  hadoop login commit
2015-12-17 16:44:51  [ main:158 ] - [ DEBUG ]  using local user:NTUserPrincipal: Administrator
2015-12-17 16:44:51  [ main:159 ] - [ DEBUG ]  UGI loginUser:Administrator (auth:SIMPLE)
2015-12-17 16:44:51  [ main:335 ] - [ DEBUG ]  Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:225)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:250)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.conf.Configuration.getStrings(Configuration.java:1514)
	at org.apache.hadoop.hbase.zookeeper.ZKConfig.makeZKProps(ZKConfig.java:113)
	at org.apache.hadoop.hbase.zookeeper.ZKConfig.getZKQuorumServersString(ZKConfig.java:265)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:159)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:134)
	at org.apache.hadoop.hbase.client.ZooKeeperKeepAliveConnection.<init>(ZooKeeperKeepAliveConnection.java:43)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getKeepAliveZooKeeperWatcher(HConnectionManager.java:1769)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:82)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.retrieveClusterId(HConnectionManager.java:858)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.<init>(HConnectionManager.java:663)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:415)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:394)
	at org.apache.hadoop.hbase.client.HConnectionManager.getConnection(HConnectionManager.java:275)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:192)
	at com.ipinyou.hbase.utils.HbaseCommonUtils.delete(HbaseCommonUtils.java:112)
	at com.ipinyou.hbase.utils.HbaseCommonUtils.main(HbaseCommonUtils.java:129)
2015-12-17 16:44:51  [ main:337 ] - [ ERROR ]  Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:278)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:300)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:293)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.conf.Configuration.getStrings(Configuration.java:1514)
	at org.apache.hadoop.hbase.zookeeper.ZKConfig.makeZKProps(ZKConfig.java:113)
	at org.apache.hadoop.hbase.zookeeper.ZKConfig.getZKQuorumServersString(ZKConfig.java:265)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:159)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:134)
	at org.apache.hadoop.hbase.client.ZooKeeperKeepAliveConnection.<init>(ZooKeeperKeepAliveConnection.java:43)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getKeepAliveZooKeeperWatcher(HConnectionManager.java:1769)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:82)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.retrieveClusterId(HConnectionManager.java:858)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.<init>(HConnectionManager.java:663)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:415)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:394)
	at org.apache.hadoop.hbase.client.HConnectionManager.getConnection(HConnectionManager.java:275)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:192)
	at com.ipinyou.hbase.utils.HbaseCommonUtils.delete(HbaseCommonUtils.java:112)
	at com.ipinyou.hbase.utils.HbaseCommonUtils.main(HbaseCommonUtils.java:129)
2015-12-17 16:44:51  [ main:396 ] - [ INFO ]  Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2015-12-17 16:44:51  [ main:396 ] - [ INFO ]  Client environment:host.name=10.1.2.39
2015-12-17 16:44:51  [ main:396 ] - [ INFO ]  Client environment:java.version=1.8.0_60
2015-12-17 16:44:51  [ main:396 ] - [ INFO ]  Client environment:java.vendor=Oracle Corporation
2015-12-17 16:44:51  [ main:396 ] - [ INFO ]  Client environment:java.home=C:\Program Files\Java\jdk1.8.0_60\jre
2015-12-17 16:44:51  [ main:396 ] - [ INFO ]  Client environment:java.class.path=E:\adunit\hadoop-tool\target\classes;E:\mavenrepository\log4j\log4j\1.2.14\log4j-1.2.14.jar;E:\mavenrepository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;E:\mavenrepository\org\apache\hbase\hbase-client\0.98.4-hadoop2\hbase-client-0.98.4-hadoop2.jar;E:\mavenrepository\org\apache\hbase\hbase-common\0.98.4-hadoop2\hbase-common-0.98.4-hadoop2.jar;E:\mavenrepository\org\apache\hbase\hbase-protocol\0.98.4-hadoop2\hbase-protocol-0.98.4-hadoop2.jar;E:\mavenrepository\commons-codec\commons-codec\1.7\commons-codec-1.7.jar;E:\mavenrepository\commons-io\commons-io\2.4\commons-io-2.4.jar;E:\mavenrepository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;E:\mavenrepository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;E:\mavenrepository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;E:\mavenrepository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;E:\mavenrepository\io\netty\netty\3.6.6.Final\netty-3.6.6.Final.jar;E:\mavenrepository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;E:\mavenrepository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;E:\mavenrepository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;E:\mavenrepository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;E:\mavenrepository\org\codehaus\jackson\jackson-mapper-asl\1.8.8\jackson-mapper-asl-1.8.8.jar;E:\mavenrepository\org\apache\hadoop\hadoop-common\2.2.0\hadoop-common-2.2.0.jar;E:\mavenrepository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;E:\mavenrepository\commons-net\commons-net\3.1\commons-net-3.1.jar;E:\mavenrepository\commons-el\commons-el\1.0\commons-el-1.0.jar;E:\mavenrepository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;E:\mavenrepository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;E:\mavenrepository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;E:\mavenrepository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;E:\mavenrepository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;E:\mavenrepository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;E:\mavenrepository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;E:\mavenrepository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;E:\mavenrepository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;E:\mavenrepository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;E:\mavenrepository\org\tukaani\xz\1.0\xz-1.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-mapreduce-client-core\2.2.0\hadoop-mapreduce-client-core-2.2.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;E:\mavenrepository\com\google\inject\guice\3.0\guice-3.0.jar;E:\mavenrepository\javax\inject\javax.inject\1\javax.inject-1.jar;E:\mavenrepository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;E:\mavenrepository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;E:\mavenrepository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-annotations\2.2.0\hadoop-annotations-2.2.0.jar;E:\mavenrepository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;E:\mavenrepository\org\apache\hbase\hbase-server\0.98.4-hadoop2\hbase-server-0.98.4-hadoop2.jar;E:\mavenrepository\org\apache\hbase\hbase-prefix-tree\0.98.4-hadoop2\hbase-prefix-tree-0.98.4-hadoop2.jar;E:\mavenrepository\org\apache\hbase\hbase-common\0.98.4-hadoop2\hbase-common-0.98.4-hadoop2-tests.jar;E:\mavenrepository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;E:\mavenrepository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;E:\mavenrepository\org\apache\hbase\hbase-hadoop2-compat\0.98.4-hadoop2\hbase-hadoop2-compat-0.98.4-hadoop2.jar;E:\mavenrepository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;E:\mavenrepository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;E:\mavenrepository\com\github\stephenc\high-scale-lib\high-scale-lib\1.1.1\high-scale-lib-1.1.1.jar;E:\mavenrepository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;E:\mavenrepository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;E:\mavenrepository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;E:\mavenrepository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;E:\mavenrepository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;E:\mavenrepository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;E:\mavenrepository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;E:\mavenrepository\org\codehaus\jackson\jackson-core-asl\1.8.8\jackson-core-asl-1.8.8.jar;E:\mavenrepository\org\codehaus\jackson\jackson-jaxrs\1.8.8\jackson-jaxrs-1.8.8.jar;E:\mavenrepository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;E:\mavenrepository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;E:\mavenrepository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;E:\mavenrepository\com\sun\jersey\jersey-core\1.8\jersey-core-1.8.jar;E:\mavenrepository\com\sun\jersey\jersey-json\1.8\jersey-json-1.8.jar;E:\mavenrepository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;E:\mavenrepository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;E:\mavenrepository\org\codehaus\jackson\jackson-xc\1.7.1\jackson-xc-1.7.1.jar;E:\mavenrepository\com\sun\jersey\jersey-server\1.8\jersey-server-1.8.jar;E:\mavenrepository\asm\asm\3.1\asm-3.1.jar;E:\mavenrepository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;E:\mavenrepository\javax\activation\activation\1.1\activation-1.1.jar;E:\mavenrepository\org\apache\hadoop\hadoop-hdfs\2.2.0\hadoop-hdfs-2.2.0.jar;E:\mavenrepository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;E:\mavenrepository\org\apache\hbase\hbase-hadoop-compat\0.98.4-hadoop2\hbase-hadoop-compat-0.98.4-hadoop2.jar;E:\mavenrepository\org\apache\hadoop\hadoop-client\2.4.0\hadoop-client-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-mapreduce-client-app\2.4.0\hadoop-mapreduce-client-app-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-mapreduce-client-common\2.4.0\hadoop-mapreduce-client-common-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-yarn-client\2.4.0\hadoop-yarn-client-2.4.0.jar;E:\mavenrepository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;E:\mavenrepository\org\apache\hadoop\hadoop-yarn-server-common\2.4.0\hadoop-yarn-server-common-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.4.0\hadoop-mapreduce-client-shuffle-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-yarn-api\2.4.0\hadoop-yarn-api-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.4.0\hadoop-mapreduce-client-jobclient-2.4.0.jar;C:\Program Files\Java\jdk1.8.0_60\lib\tools.jar
2015-12-17 16:44:51  [ main:397 ] - [ INFO ]  Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_60\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jre1.8.0_66/bin/server;C:/Program Files/Java/jre1.8.0_66/bin;C:/Program Files/Java/jre1.8.0_66/lib/amd64;C:\ProgramData\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Java\jdk1.8.0_60\bin;D:\developtools\maven\apache-maven-3.2.3-bin\apache-maven-3.2.3\bin;D:\Program Files (x86)\Git\cmd;D:\snapshot;D:\Program Files\TortoiseSVN\bin;D:\developtools\apache-ant-1.9.4\bin;D:\Program Files (x86)\scala\bin;C:\Program Files (x86)\scala\bin;D:\Program Files (x86)\OpenVPN\bin;D:\developtools\eclipse64\eclipse;;.
2015-12-17 16:44:51  [ main:397 ] - [ INFO ]  Client environment:java.io.tmpdir=C:\Users\ADMINI~1.K5Y\AppData\Local\Temp\
2015-12-17 16:44:51  [ main:397 ] - [ INFO ]  Client environment:java.compiler=<NA>
2015-12-17 16:44:51  [ main:397 ] - [ INFO ]  Client environment:os.name=Windows 7
2015-12-17 16:44:51  [ main:397 ] - [ INFO ]  Client environment:os.arch=amd64
2015-12-17 16:44:51  [ main:397 ] - [ INFO ]  Client environment:os.version=6.1
2015-12-17 16:44:51  [ main:397 ] - [ INFO ]  Client environment:user.name=Administrator
2015-12-17 16:44:51  [ main:397 ] - [ INFO ]  Client environment:user.home=C:\Users\Administrator.K5YUPM1XIRO9YVM
2015-12-17 16:44:51  [ main:397 ] - [ INFO ]  Client environment:user.dir=E:\adunit\hadoop-tool
2015-12-17 16:44:51  [ main:398 ] - [ INFO ]  Initiating client connection, connectString=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181 sessionTimeout=30000 watcher=hconnection-0x2b552920, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure
2015-12-17 16:44:51  [ main:401 ] - [ DEBUG ]  zookeeper.disableAutoWatchReset is false
2015-12-17 16:44:51  [ main-SendThread(storm14665:2181):490 ] - [ INFO ]  Opening socket connection to server storm14665/192.168.146.65:2181. Will not attempt to authenticate using SASL (unknown error)
2015-12-17 16:44:51  [ main:491 ] - [ INFO ]  Process identifier=hconnection-0x2b552920 connecting to ZooKeeper ensemble=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181
2015-12-17 16:44:51  [ main-SendThread(storm14665:2181):497 ] - [ INFO ]  Socket connection established to storm14665/192.168.146.65:2181, initiating session
2015-12-17 16:44:51  [ main-SendThread(storm14665:2181):498 ] - [ DEBUG ]  Session establishment request sent on storm14665/192.168.146.65:2181
2015-12-17 16:44:51  [ main-SendThread(storm14665:2181):746 ] - [ INFO ]  Session establishment complete on server storm14665/192.168.146.65:2181, sessionid = 0x6519036dd300348, negotiated timeout = 30000
2015-12-17 16:44:51  [ main-EventThread:752 ] - [ DEBUG ]  hconnection-0x2b552920, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2015-12-17 16:44:51  [ main-EventThread:755 ] - [ DEBUG ]  hconnection-0x2b552920-0x6519036dd300348 connected
2015-12-17 16:44:52  [ main-SendThread(storm14665:2181):956 ] - [ DEBUG ]  Reading reply sessionid:0x6519036dd300348, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,438132927223,0  request:: '/hbase-unsecure/hbaseid,F  response:: s{154655491313,438112239238,1432008035942,1449675376357,3,0,0,0,67,0,154655491313} 
2015-12-17 16:44:52  [ main-SendThread(storm14665:2181):964 ] - [ DEBUG ]  Reading reply sessionid:0x6519036dd300348, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,438132927230,0  request:: '/hbase-unsecure/hbaseid,F  response:: #ffffffff000146d61737465723a36303030304fffffffef1ffffffffdffffff8b62553d50425546a2439666666343534382d643935652d343637352d626635652d623035626335363434353537,s{154655491313,438112239238,1432008035942,1449675376357,3,0,0,0,67,0,154655491313} 
2015-12-17 16:44:52  [ main:1149 ] - [ DEBUG ]  Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@13c10b87, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2015-12-17 16:44:52  [ main:1159 ] - [ INFO ]  Initiating client connection, connectString=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181 sessionTimeout=30000 watcher=catalogtracker-on-hconnection-0x2b552920, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure
2015-12-17 16:44:52  [ main:1163 ] - [ INFO ]  Process identifier=catalogtracker-on-hconnection-0x2b552920 connecting to ZooKeeper ensemble=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181
2015-12-17 16:44:52  [ main-SendThread(storm14656:2181):1163 ] - [ INFO ]  Opening socket connection to server storm14656/192.168.146.56:2181. Will not attempt to authenticate using SASL (unknown error)
2015-12-17 16:44:52  [ main:1164 ] - [ DEBUG ]  Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3b07a0d6
2015-12-17 16:44:52  [ main-SendThread(storm14656:2181):1215 ] - [ INFO ]  Socket connection established to storm14656/192.168.146.56:2181, initiating session
2015-12-17 16:44:52  [ main-SendThread(storm14656:2181):1215 ] - [ DEBUG ]  Session establishment request sent on storm14656/192.168.146.56:2181
2015-12-17 16:44:52  [ main-SendThread(storm14656:2181):1465 ] - [ INFO ]  Session establishment complete on server storm14656/192.168.146.56:2181, sessionid = 0x4515656862bdbd7, negotiated timeout = 30000
2015-12-17 16:44:52  [ main-EventThread:1465 ] - [ DEBUG ]  catalogtracker-on-hconnection-0x2b552920, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2015-12-17 16:44:52  [ main-EventThread:1466 ] - [ DEBUG ]  catalogtracker-on-hconnection-0x2b552920-0x4515656862bdbd7 connected
2015-12-17 16:44:52  [ main-SendThread(storm14656:2181):1471 ] - [ DEBUG ]  Reading reply sessionid:0x4515656862bdbd7, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,438132927249,0  request:: '/hbase-unsecure/meta-region-server,T  response:: s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 16:44:52  [ main:1471 ] - [ DEBUG ]  catalogtracker-on-hconnection-0x2b552920-0x4515656862bdbd7, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure Set watcher on existing znode=/hbase-unsecure/meta-region-server
2015-12-17 16:44:52  [ main-SendThread(storm14656:2181):1476 ] - [ DEBUG ]  Reading reply sessionid:0x4515656862bdbd7, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,438132927249,0  request:: '/hbase-unsecure/meta-region-server,T  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffff8dffffffebffffffb3516fffffffd2ffffffb0650425546a19ac6861646f6f7031343631393010fffffff4ffffffd4318ffffffb1ffffffa9ffffff8bffffffbbffffff982a100,s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 16:44:52  [ main:1557 ] - [ INFO ]  hadoop.native.lib is deprecated. Instead, use io.native.lib.available
2015-12-17 16:44:52  [ main-SendThread(storm14665:2181):1720 ] - [ DEBUG ]  Reading reply sessionid:0x6519036dd300348, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,438132927254,0  request:: '/hbase-unsecure/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffff8dffffffebffffffb3516fffffffd2ffffffb0650425546a19ac6861646f6f7031343631393010fffffff4ffffffd4318ffffffb1ffffffa9ffffff8bffffffbbffffff982a100,s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 16:44:52  [ main:1846 ] - [ DEBUG ]  Use SIMPLE authentication for service ClientService, sasl=false
2015-12-17 16:44:52  [ main:1851 ] - [ DEBUG ]  Connecting to hadoop146190/192.168.146.190:60020
2015-12-17 16:44:52  [ IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator:1867 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: starting, connections 1
2015-12-17 16:44:52  [ main:1877 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 0 method_name: "Scan" request_param: true
2015-12-17 16:44:52  [ IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator:1937 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 0, totalSize: 20 bytes
2015-12-17 16:44:53  [ main:1944 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 1 method_name: "Scan" request_param: true priority: 100
2015-12-17 16:44:53  [ IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator:1962 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 1 cell_block_meta { length: 5768 }, totalSize: 5817 bytes
2015-12-17 16:44:53  [ main:1978 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 2 method_name: "Scan" request_param: true
2015-12-17 16:44:53  [ IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator:2009 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 2, totalSize: 16 bytes
2015-12-17 16:44:53  [ main:2026 ] - [ DEBUG ]  Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3b07a0d6
2015-12-17 16:44:53  [ main:2026 ] - [ DEBUG ]  Closing session: 0x4515656862bdbd7
2015-12-17 16:44:53  [ main:2027 ] - [ DEBUG ]  Closing client for session: 0x4515656862bdbd7
2015-12-17 16:44:53  [ main-SendThread(storm14656:2181):2036 ] - [ DEBUG ]  Reading reply sessionid:0x4515656862bdbd7, packet:: clientPath:null serverPath:null finished:false header:: 3,-11  replyHeader:: 3,438132927267,0  request:: null response:: null
2015-12-17 16:44:53  [ main:2036 ] - [ DEBUG ]  Disconnecting client for session: 0x4515656862bdbd7
2015-12-17 16:44:53  [ main:2036 ] - [ INFO ]  Session: 0x4515656862bdbd7 closed
2015-12-17 16:44:53  [ main-EventThread:2036 ] - [ INFO ]  EventThread shut down
2015-12-17 16:44:53  [ main-SendThread(storm14665:2181):2085 ] - [ DEBUG ]  Reading reply sessionid:0x6519036dd300348, packet:: clientPath:null serverPath:null finished:false header:: 4,3  replyHeader:: 4,438132927270,0  request:: '/hbase-unsecure,F  response:: s{90194321419,90194321419,1410501665281,1410501665281,0,83,0,0,0,15,438112239529} 
2015-12-17 16:44:53  [ main-SendThread(storm14665:2181):2090 ] - [ DEBUG ]  Reading reply sessionid:0x6519036dd300348, packet:: clientPath:null serverPath:null finished:false header:: 5,4  replyHeader:: 5,438132927270,0  request:: '/hbase-unsecure/master,F  response:: #ffffffff000146d61737465723a36303030304bffffff95ffffffb0ffffffb4ffffff9947ff50425546a18ab6861646f6f70313436393110ffffffe0ffffffd4318ffffffc3fffffff6ffffff8affffffbbffffff982a100,s{438112239199,438112239199,1449675375401,1449675375401,0,0,0,671412749073908824,57,0,438112239199} 
2015-12-17 16:44:53  [ main:2241 ] - [ DEBUG ]  Use SIMPLE authentication for service MasterService, sasl=false
2015-12-17 16:44:53  [ main:2241 ] - [ DEBUG ]  Connecting to hadoop14691/192.168.146.91:60000
2015-12-17 16:44:53  [ IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator:2254 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator: starting, connections 2
2015-12-17 16:44:53  [ main:2254 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator: wrote request header call_id: 3 method_name: "IsMasterRunning" request_param: true
2015-12-17 16:44:53  [ IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator:2342 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator: got response header call_id: 3, totalSize: 6 bytes
2015-12-17 16:44:53  [ main:2386 ] - [ INFO ]  Started disable of adunit
2015-12-17 16:44:53  [ main:2536 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator: wrote request header call_id: 4 method_name: "DisableTable" request_param: true
2015-12-17 16:44:53  [ IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator:2560 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator: got response header call_id: 4, totalSize: 4 bytes
2015-12-17 16:44:53  [ main:2616 ] - [ INFO ]  Initiating client connection, connectString=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181 sessionTimeout=30000 watcher=catalogtracker-on-hconnection-0x2b552920, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure
2015-12-17 16:44:53  [ main:2620 ] - [ INFO ]  Process identifier=catalogtracker-on-hconnection-0x2b552920 connecting to ZooKeeper ensemble=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181
2015-12-17 16:44:53  [ main:2623 ] - [ DEBUG ]  Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@2df9b86
2015-12-17 16:44:53  [ main-SendThread(storm14667:2181):2623 ] - [ INFO ]  Opening socket connection to server storm14667/192.168.146.67:2181. Will not attempt to authenticate using SASL (unknown error)
2015-12-17 16:44:53  [ main-SendThread(storm14667:2181):2629 ] - [ INFO ]  Socket connection established to storm14667/192.168.146.67:2181, initiating session
2015-12-17 16:44:53  [ main-SendThread(storm14667:2181):2629 ] - [ DEBUG ]  Session establishment request sent on storm14667/192.168.146.67:2181
2015-12-17 16:44:53  [ main-SendThread(storm14667:2181):2762 ] - [ INFO ]  Session establishment complete on server storm14667/192.168.146.67:2181, sessionid = 0x751775964180606, negotiated timeout = 30000
2015-12-17 16:44:53  [ main-EventThread:2764 ] - [ DEBUG ]  catalogtracker-on-hconnection-0x2b552920, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2015-12-17 16:44:53  [ main-EventThread:2765 ] - [ DEBUG ]  catalogtracker-on-hconnection-0x2b552920-0x751775964180606 connected
2015-12-17 16:44:53  [ main-SendThread(storm14667:2181):2768 ] - [ DEBUG ]  Reading reply sessionid:0x751775964180606, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,438132927295,0  request:: '/hbase-unsecure/meta-region-server,T  response:: s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 16:44:53  [ main:2768 ] - [ DEBUG ]  catalogtracker-on-hconnection-0x2b552920-0x751775964180606, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure Set watcher on existing znode=/hbase-unsecure/meta-region-server
2015-12-17 16:44:53  [ main-SendThread(storm14667:2181):2777 ] - [ DEBUG ]  Reading reply sessionid:0x751775964180606, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,438132927295,0  request:: '/hbase-unsecure/meta-region-server,T  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffff8dffffffebffffffb3516fffffffd2ffffffb0650425546a19ac6861646f6f7031343631393010fffffff4ffffffd4318ffffffb1ffffffa9ffffff8bffffffbbffffff982a100,s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 16:44:53  [ main-SendThread(storm14665:2181):2783 ] - [ DEBUG ]  Reading reply sessionid:0x6519036dd300348, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,438132927295,0  request:: '/hbase-unsecure/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffff8dffffffebffffffb3516fffffffd2ffffffb0650425546a19ac6861646f6f7031343631393010fffffff4ffffffd4318ffffffb1ffffffa9ffffff8bffffffbbffffff982a100,s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 16:44:53  [ main:2784 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 5 method_name: "Scan" request_param: true
2015-12-17 16:44:53  [ IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator:2787 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 5, totalSize: 20 bytes
2015-12-17 16:44:53  [ main:2788 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 6 method_name: "Scan" request_param: true priority: 100
2015-12-17 16:44:53  [ IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator:2807 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 6 cell_block_meta { length: 5768 }, totalSize: 5817 bytes
2015-12-17 16:44:53  [ main:2808 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 7 method_name: "Scan" request_param: true
2015-12-17 16:44:53  [ IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator:2854 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 7, totalSize: 16 bytes
2015-12-17 16:44:53  [ main:2855 ] - [ DEBUG ]  Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@2df9b86
2015-12-17 16:44:53  [ main:2857 ] - [ DEBUG ]  Closing session: 0x751775964180606
2015-12-17 16:44:53  [ main:2857 ] - [ DEBUG ]  Closing client for session: 0x751775964180606
2015-12-17 16:44:53  [ main-SendThread(storm14667:2181):2864 ] - [ DEBUG ]  Reading reply sessionid:0x751775964180606, packet:: clientPath:null serverPath:null finished:false header:: 3,-11  replyHeader:: 3,438132927299,0  request:: null response:: null
2015-12-17 16:44:53  [ main:2864 ] - [ DEBUG ]  Disconnecting client for session: 0x751775964180606
2015-12-17 16:44:53  [ main:2864 ] - [ INFO ]  Session: 0x751775964180606 closed
2015-12-17 16:44:53  [ main-EventThread:2865 ] - [ INFO ]  EventThread shut down
2015-12-17 16:44:53  [ main-SendThread(storm14665:2181):2874 ] - [ DEBUG ]  Reading reply sessionid:0x6519036dd300348, packet:: clientPath:null serverPath:null finished:false header:: 7,4  replyHeader:: 7,438132927299,0  request:: '/hbase-unsecure/table/adunit,F  response:: #ffffffff000146d61737465723a36303030302e41ffffff9d7ffffffec62ffffffe35f5042554682,s{438098213790,438132927287,1449224495406,1450341906171,4,0,0,0,31,0,438098213790} 
2015-12-17 16:44:53  [ main:2911 ] - [ DEBUG ]  Sleeping= 100ms, waiting for all regions to be disabled in adunit
2015-12-17 16:44:54  [ main:3013 ] - [ INFO ]  Initiating client connection, connectString=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181 sessionTimeout=30000 watcher=catalogtracker-on-hconnection-0x2b552920, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure
2015-12-17 16:44:54  [ main:3025 ] - [ INFO ]  Process identifier=catalogtracker-on-hconnection-0x2b552920 connecting to ZooKeeper ensemble=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181
2015-12-17 16:44:54  [ main:3025 ] - [ DEBUG ]  Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@1e683a3e
2015-12-17 16:44:54  [ main-SendThread(storm14667:2181):3026 ] - [ INFO ]  Opening socket connection to server storm14667/192.168.146.67:2181. Will not attempt to authenticate using SASL (unknown error)
2015-12-17 16:44:54  [ main-SendThread(storm14667:2181):3030 ] - [ INFO ]  Socket connection established to storm14667/192.168.146.67:2181, initiating session
2015-12-17 16:44:54  [ main-SendThread(storm14667:2181):3030 ] - [ DEBUG ]  Session establishment request sent on storm14667/192.168.146.67:2181
2015-12-17 16:44:54  [ main-SendThread(storm14667:2181):3274 ] - [ INFO ]  Session establishment complete on server storm14667/192.168.146.67:2181, sessionid = 0x751775964180607, negotiated timeout = 30000
2015-12-17 16:44:54  [ main-EventThread:3274 ] - [ DEBUG ]  catalogtracker-on-hconnection-0x2b552920, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2015-12-17 16:44:54  [ main-EventThread:3276 ] - [ DEBUG ]  catalogtracker-on-hconnection-0x2b552920-0x751775964180607 connected
2015-12-17 16:44:54  [ main-SendThread(storm14667:2181):3280 ] - [ DEBUG ]  Reading reply sessionid:0x751775964180607, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,438132927315,0  request:: '/hbase-unsecure/meta-region-server,T  response:: s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 16:44:54  [ main:3281 ] - [ DEBUG ]  catalogtracker-on-hconnection-0x2b552920-0x751775964180607, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure Set watcher on existing znode=/hbase-unsecure/meta-region-server
2015-12-17 16:44:54  [ main-SendThread(storm14667:2181):3288 ] - [ DEBUG ]  Reading reply sessionid:0x751775964180607, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,438132927315,0  request:: '/hbase-unsecure/meta-region-server,T  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffff8dffffffebffffffb3516fffffffd2ffffffb0650425546a19ac6861646f6f7031343631393010fffffff4ffffffd4318ffffffb1ffffffa9ffffff8bffffffbbffffff982a100,s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 16:44:54  [ main-SendThread(storm14665:2181):3298 ] - [ DEBUG ]  Reading reply sessionid:0x6519036dd300348, packet:: clientPath:null serverPath:null finished:false header:: 8,4  replyHeader:: 8,438132927315,0  request:: '/hbase-unsecure/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffff8dffffffebffffffb3516fffffffd2ffffffb0650425546a19ac6861646f6f7031343631393010fffffff4ffffffd4318ffffffb1ffffffa9ffffff8bffffffbbffffff982a100,s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 16:44:54  [ main:3299 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 8 method_name: "Scan" request_param: true
2015-12-17 16:44:54  [ IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator:3302 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 8, totalSize: 20 bytes
2015-12-17 16:44:54  [ main:3303 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 9 method_name: "Scan" request_param: true priority: 100
2015-12-17 16:44:54  [ IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator:3319 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 9 cell_block_meta { length: 5768 }, totalSize: 5817 bytes
2015-12-17 16:44:54  [ main:3320 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 10 method_name: "Scan" request_param: true
2015-12-17 16:44:54  [ IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator:3364 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 10, totalSize: 16 bytes
2015-12-17 16:44:54  [ main:3364 ] - [ DEBUG ]  Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@1e683a3e
2015-12-17 16:44:54  [ main:3364 ] - [ DEBUG ]  Closing session: 0x751775964180607
2015-12-17 16:44:54  [ main:3364 ] - [ DEBUG ]  Closing client for session: 0x751775964180607
2015-12-17 16:44:54  [ main-SendThread(storm14667:2181):3371 ] - [ DEBUG ]  Reading reply sessionid:0x751775964180607, packet:: clientPath:null serverPath:null finished:false header:: 3,-11  replyHeader:: 3,438132927320,0  request:: null response:: null
2015-12-17 16:44:54  [ main:3371 ] - [ DEBUG ]  Disconnecting client for session: 0x751775964180607
2015-12-17 16:44:54  [ main:3371 ] - [ INFO ]  Session: 0x751775964180607 closed
2015-12-17 16:44:54  [ main-EventThread:3371 ] - [ INFO ]  EventThread shut down
2015-12-17 16:44:54  [ main-SendThread(storm14665:2181):3379 ] - [ DEBUG ]  Reading reply sessionid:0x6519036dd300348, packet:: clientPath:null serverPath:null finished:false header:: 9,4  replyHeader:: 9,438132927321,0  request:: '/hbase-unsecure/table/adunit,F  response:: #ffffffff000146d61737465723a36303030302e41ffffff9d7ffffffec62ffffffe35f5042554682,s{438098213790,438132927287,1449224495406,1450341906171,4,0,0,0,31,0,438098213790} 
2015-12-17 16:44:54  [ main:3379 ] - [ DEBUG ]  Sleeping= 200ms, waiting for all regions to be disabled in adunit
2015-12-17 16:44:54  [ main:3581 ] - [ INFO ]  Initiating client connection, connectString=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181 sessionTimeout=30000 watcher=catalogtracker-on-hconnection-0x2b552920, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure
2015-12-17 16:44:54  [ main:3586 ] - [ INFO ]  Process identifier=catalogtracker-on-hconnection-0x2b552920 connecting to ZooKeeper ensemble=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181
2015-12-17 16:44:54  [ main:3587 ] - [ DEBUG ]  Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@7a419da4
2015-12-17 16:44:54  [ main-SendThread(storm14665:2181):3587 ] - [ INFO ]  Opening socket connection to server storm14665/192.168.146.65:2181. Will not attempt to authenticate using SASL (unknown error)
2015-12-17 16:44:54  [ main-SendThread(storm14665:2181):3603 ] - [ INFO ]  Socket connection established to storm14665/192.168.146.65:2181, initiating session
2015-12-17 16:44:54  [ main-SendThread(storm14665:2181):3603 ] - [ DEBUG ]  Session establishment request sent on storm14665/192.168.146.65:2181
2015-12-17 16:44:54  [ main-SendThread(storm14665:2181):3855 ] - [ INFO ]  Session establishment complete on server storm14665/192.168.146.65:2181, sessionid = 0x6519036dd300349, negotiated timeout = 30000
2015-12-17 16:44:54  [ main-EventThread:3856 ] - [ DEBUG ]  catalogtracker-on-hconnection-0x2b552920, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2015-12-17 16:44:54  [ main-EventThread:3858 ] - [ DEBUG ]  catalogtracker-on-hconnection-0x2b552920-0x6519036dd300349 connected
2015-12-17 16:44:54  [ main-SendThread(storm14665:2181):3860 ] - [ DEBUG ]  Reading reply sessionid:0x6519036dd300349, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,438132927339,0  request:: '/hbase-unsecure/meta-region-server,T  response:: s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 16:44:54  [ main:3860 ] - [ DEBUG ]  catalogtracker-on-hconnection-0x2b552920-0x6519036dd300349, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure Set watcher on existing znode=/hbase-unsecure/meta-region-server
2015-12-17 16:44:54  [ main-SendThread(storm14665:2181):3888 ] - [ DEBUG ]  Reading reply sessionid:0x6519036dd300349, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,438132927340,0  request:: '/hbase-unsecure/meta-region-server,T  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffff8dffffffebffffffb3516fffffffd2ffffffb0650425546a19ac6861646f6f7031343631393010fffffff4ffffffd4318ffffffb1ffffffa9ffffff8bffffffbbffffff982a100,s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 16:44:54  [ main-SendThread(storm14665:2181):3917 ] - [ DEBUG ]  Reading reply sessionid:0x6519036dd300348, packet:: clientPath:null serverPath:null finished:false header:: 10,4  replyHeader:: 10,438132927341,0  request:: '/hbase-unsecure/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffff8dffffffebffffffb3516fffffffd2ffffffb0650425546a19ac6861646f6f7031343631393010fffffff4ffffffd4318ffffffb1ffffffa9ffffff8bffffffbbffffff982a100,s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 16:44:54  [ main:3917 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 11 method_name: "Scan" request_param: true
2015-12-17 16:44:54  [ IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator:3920 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 11, totalSize: 20 bytes
2015-12-17 16:44:54  [ main:3921 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 12 method_name: "Scan" request_param: true priority: 100
2015-12-17 16:44:54  [ IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator:3937 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 12 cell_block_meta { length: 5768 }, totalSize: 5817 bytes
2015-12-17 16:44:54  [ main:3938 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 13 method_name: "Scan" request_param: true
2015-12-17 16:44:55  [ IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator:3982 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 13, totalSize: 16 bytes
2015-12-17 16:44:55  [ main:3983 ] - [ DEBUG ]  Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@7a419da4
2015-12-17 16:44:55  [ main:3983 ] - [ DEBUG ]  Closing session: 0x6519036dd300349
2015-12-17 16:44:55  [ main:3983 ] - [ DEBUG ]  Closing client for session: 0x6519036dd300349
2015-12-17 16:44:55  [ main-SendThread(storm14665:2181):3997 ] - [ DEBUG ]  Reading reply sessionid:0x6519036dd300349, packet:: clientPath:null serverPath:null finished:false header:: 3,-11  replyHeader:: 3,438132927347,0  request:: null response:: null
2015-12-17 16:44:55  [ main:3997 ] - [ DEBUG ]  Disconnecting client for session: 0x6519036dd300349
2015-12-17 16:44:55  [ main:3997 ] - [ INFO ]  Session: 0x6519036dd300349 closed
2015-12-17 16:44:55  [ main-EventThread:3997 ] - [ INFO ]  EventThread shut down
2015-12-17 16:44:55  [ main-SendThread(storm14665:2181):4005 ] - [ DEBUG ]  Reading reply sessionid:0x6519036dd300348, packet:: clientPath:null serverPath:null finished:false header:: 11,4  replyHeader:: 11,438132927347,0  request:: '/hbase-unsecure/table/adunit,F  response:: #ffffffff000146d61737465723a363030303018ffffff97ffffffef79ffffff88fffffffaffffffa9235042554681,s{438098213790,438132927331,1449224495406,1450341907176,5,0,0,0,31,0,438098213790} 
2015-12-17 16:44:55  [ main:4005 ] - [ INFO ]  Disabled adunit
2015-12-17 16:44:55  [ main:4005 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator: wrote request header call_id: 14 method_name: "IsMasterRunning" request_param: true
2015-12-17 16:44:55  [ IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator:4008 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator: got response header call_id: 14, totalSize: 6 bytes
2015-12-17 16:44:55  [ main:4118 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator: wrote request header call_id: 15 method_name: "DeleteTable" request_param: true
2015-12-17 16:44:55  [ IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator:4378 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator: got response header call_id: 15, totalSize: 4 bytes
2015-12-17 16:44:55  [ main-SendThread(storm14665:2181):4407 ] - [ DEBUG ]  Reading reply sessionid:0x6519036dd300348, packet:: clientPath:null serverPath:null finished:false header:: 12,4  replyHeader:: 12,438132927362,0  request:: '/hbase-unsecure/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffff8dffffffebffffffb3516fffffffd2ffffffb0650425546a19ac6861646f6f7031343631393010fffffff4ffffffd4318ffffffb1ffffffa9ffffff8bffffffbbffffff982a100,s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 16:44:55  [ main:4430 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 16 method_name: "Scan" request_param: true
2015-12-17 16:44:55  [ IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator:4434 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 16, totalSize: 16 bytes
2015-12-17 16:44:55  [ main:4435 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator: wrote request header call_id: 17 method_name: "IsMasterRunning" request_param: true
2015-12-17 16:44:55  [ IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator:4608 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator: got response header call_id: 17, totalSize: 6 bytes
2015-12-17 16:44:55  [ main:4667 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator: wrote request header call_id: 18 method_name: "GetTableDescriptors" request_param: true
2015-12-17 16:44:55  [ IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator:4676 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator: got response header call_id: 18, totalSize: 4 bytes
2015-12-17 16:44:55  [ main:4703 ] - [ INFO ]  Deleted adunit
2015-12-17 16:48:44  [ main:0 ] - [ DEBUG ]  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
2015-12-17 16:48:44  [ main:14 ] - [ DEBUG ]  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
2015-12-17 16:48:44  [ main:15 ] - [ DEBUG ]  UgiMetrics, User and group related metrics
2015-12-17 16:48:45  [ main:146 ] - [ DEBUG ]  Kerberos krb5 configuration not found, setting default realm to empty
2015-12-17 16:48:45  [ main:148 ] - [ DEBUG ]   Creating new Groups object
2015-12-17 16:48:45  [ main:152 ] - [ DEBUG ]  Trying to load the custom-built native-hadoop library...
2015-12-17 16:48:45  [ main:154 ] - [ DEBUG ]  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-12-17 16:48:45  [ main:154 ] - [ DEBUG ]  java.library.path=C:\Program Files\Java\jdk1.8.0_60\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jre1.8.0_66/bin/server;C:/Program Files/Java/jre1.8.0_66/bin;C:/Program Files/Java/jre1.8.0_66/lib/amd64;C:\ProgramData\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Java\jdk1.8.0_60\bin;D:\developtools\maven\apache-maven-3.2.3-bin\apache-maven-3.2.3\bin;D:\Program Files (x86)\Git\cmd;D:\snapshot;D:\Program Files\TortoiseSVN\bin;D:\developtools\apache-ant-1.9.4\bin;D:\Program Files (x86)\scala\bin;C:\Program Files (x86)\scala\bin;D:\Program Files (x86)\OpenVPN\bin;D:\developtools\eclipse64\eclipse;;.
2015-12-17 16:48:45  [ main:154 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-12-17 16:48:45  [ main:154 ] - [ DEBUG ]  Falling back to shell based
2015-12-17 16:48:45  [ main:155 ] - [ DEBUG ]  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-12-17 16:48:45  [ main:155 ] - [ DEBUG ]  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
2015-12-17 16:48:45  [ main:161 ] - [ DEBUG ]  hadoop login
2015-12-17 16:48:45  [ main:162 ] - [ DEBUG ]  hadoop login commit
2015-12-17 16:48:45  [ main:168 ] - [ DEBUG ]  using local user:NTUserPrincipal: Administrator
2015-12-17 16:48:45  [ main:170 ] - [ DEBUG ]  UGI loginUser:Administrator (auth:SIMPLE)
2015-12-17 16:48:45  [ main:348 ] - [ DEBUG ]  Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:225)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:250)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.conf.Configuration.getStrings(Configuration.java:1514)
	at org.apache.hadoop.hbase.zookeeper.ZKConfig.makeZKProps(ZKConfig.java:113)
	at org.apache.hadoop.hbase.zookeeper.ZKConfig.getZKQuorumServersString(ZKConfig.java:265)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:159)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:134)
	at org.apache.hadoop.hbase.client.ZooKeeperKeepAliveConnection.<init>(ZooKeeperKeepAliveConnection.java:43)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getKeepAliveZooKeeperWatcher(HConnectionManager.java:1769)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:82)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.retrieveClusterId(HConnectionManager.java:858)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.<init>(HConnectionManager.java:663)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:415)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:394)
	at org.apache.hadoop.hbase.client.HConnectionManager.getConnection(HConnectionManager.java:275)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:192)
	at com.ipinyou.hbase.utils.HbaseCommonUtils.creat(HbaseCommonUtils.java:38)
	at com.ipinyou.hbase.utils.HbaseCommonUtils.main(HbaseCommonUtils.java:130)
2015-12-17 16:48:45  [ main:350 ] - [ ERROR ]  Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:278)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:300)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:293)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.conf.Configuration.getStrings(Configuration.java:1514)
	at org.apache.hadoop.hbase.zookeeper.ZKConfig.makeZKProps(ZKConfig.java:113)
	at org.apache.hadoop.hbase.zookeeper.ZKConfig.getZKQuorumServersString(ZKConfig.java:265)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:159)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:134)
	at org.apache.hadoop.hbase.client.ZooKeeperKeepAliveConnection.<init>(ZooKeeperKeepAliveConnection.java:43)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getKeepAliveZooKeeperWatcher(HConnectionManager.java:1769)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:82)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.retrieveClusterId(HConnectionManager.java:858)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.<init>(HConnectionManager.java:663)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:415)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:394)
	at org.apache.hadoop.hbase.client.HConnectionManager.getConnection(HConnectionManager.java:275)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:192)
	at com.ipinyou.hbase.utils.HbaseCommonUtils.creat(HbaseCommonUtils.java:38)
	at com.ipinyou.hbase.utils.HbaseCommonUtils.main(HbaseCommonUtils.java:130)
2015-12-17 16:48:45  [ main:375 ] - [ INFO ]  Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2015-12-17 16:48:45  [ main:375 ] - [ INFO ]  Client environment:host.name=10.1.2.39
2015-12-17 16:48:45  [ main:375 ] - [ INFO ]  Client environment:java.version=1.8.0_60
2015-12-17 16:48:45  [ main:375 ] - [ INFO ]  Client environment:java.vendor=Oracle Corporation
2015-12-17 16:48:45  [ main:375 ] - [ INFO ]  Client environment:java.home=C:\Program Files\Java\jdk1.8.0_60\jre
2015-12-17 16:48:45  [ main:375 ] - [ INFO ]  Client environment:java.class.path=E:\adunit\hadoop-tool\target\classes;E:\mavenrepository\log4j\log4j\1.2.14\log4j-1.2.14.jar;E:\mavenrepository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;E:\mavenrepository\org\apache\hbase\hbase-client\0.98.4-hadoop2\hbase-client-0.98.4-hadoop2.jar;E:\mavenrepository\org\apache\hbase\hbase-common\0.98.4-hadoop2\hbase-common-0.98.4-hadoop2.jar;E:\mavenrepository\org\apache\hbase\hbase-protocol\0.98.4-hadoop2\hbase-protocol-0.98.4-hadoop2.jar;E:\mavenrepository\commons-codec\commons-codec\1.7\commons-codec-1.7.jar;E:\mavenrepository\commons-io\commons-io\2.4\commons-io-2.4.jar;E:\mavenrepository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;E:\mavenrepository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;E:\mavenrepository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;E:\mavenrepository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;E:\mavenrepository\io\netty\netty\3.6.6.Final\netty-3.6.6.Final.jar;E:\mavenrepository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;E:\mavenrepository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;E:\mavenrepository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;E:\mavenrepository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;E:\mavenrepository\org\codehaus\jackson\jackson-mapper-asl\1.8.8\jackson-mapper-asl-1.8.8.jar;E:\mavenrepository\org\apache\hadoop\hadoop-common\2.2.0\hadoop-common-2.2.0.jar;E:\mavenrepository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;E:\mavenrepository\commons-net\commons-net\3.1\commons-net-3.1.jar;E:\mavenrepository\commons-el\commons-el\1.0\commons-el-1.0.jar;E:\mavenrepository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;E:\mavenrepository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;E:\mavenrepository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;E:\mavenrepository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;E:\mavenrepository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;E:\mavenrepository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;E:\mavenrepository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;E:\mavenrepository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;E:\mavenrepository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;E:\mavenrepository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;E:\mavenrepository\org\tukaani\xz\1.0\xz-1.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-mapreduce-client-core\2.2.0\hadoop-mapreduce-client-core-2.2.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;E:\mavenrepository\com\google\inject\guice\3.0\guice-3.0.jar;E:\mavenrepository\javax\inject\javax.inject\1\javax.inject-1.jar;E:\mavenrepository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;E:\mavenrepository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;E:\mavenrepository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-annotations\2.2.0\hadoop-annotations-2.2.0.jar;E:\mavenrepository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;E:\mavenrepository\org\apache\hbase\hbase-server\0.98.4-hadoop2\hbase-server-0.98.4-hadoop2.jar;E:\mavenrepository\org\apache\hbase\hbase-prefix-tree\0.98.4-hadoop2\hbase-prefix-tree-0.98.4-hadoop2.jar;E:\mavenrepository\org\apache\hbase\hbase-common\0.98.4-hadoop2\hbase-common-0.98.4-hadoop2-tests.jar;E:\mavenrepository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;E:\mavenrepository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;E:\mavenrepository\org\apache\hbase\hbase-hadoop2-compat\0.98.4-hadoop2\hbase-hadoop2-compat-0.98.4-hadoop2.jar;E:\mavenrepository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;E:\mavenrepository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;E:\mavenrepository\com\github\stephenc\high-scale-lib\high-scale-lib\1.1.1\high-scale-lib-1.1.1.jar;E:\mavenrepository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;E:\mavenrepository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;E:\mavenrepository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;E:\mavenrepository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;E:\mavenrepository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;E:\mavenrepository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;E:\mavenrepository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;E:\mavenrepository\org\codehaus\jackson\jackson-core-asl\1.8.8\jackson-core-asl-1.8.8.jar;E:\mavenrepository\org\codehaus\jackson\jackson-jaxrs\1.8.8\jackson-jaxrs-1.8.8.jar;E:\mavenrepository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;E:\mavenrepository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;E:\mavenrepository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;E:\mavenrepository\com\sun\jersey\jersey-core\1.8\jersey-core-1.8.jar;E:\mavenrepository\com\sun\jersey\jersey-json\1.8\jersey-json-1.8.jar;E:\mavenrepository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;E:\mavenrepository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;E:\mavenrepository\org\codehaus\jackson\jackson-xc\1.7.1\jackson-xc-1.7.1.jar;E:\mavenrepository\com\sun\jersey\jersey-server\1.8\jersey-server-1.8.jar;E:\mavenrepository\asm\asm\3.1\asm-3.1.jar;E:\mavenrepository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;E:\mavenrepository\javax\activation\activation\1.1\activation-1.1.jar;E:\mavenrepository\org\apache\hadoop\hadoop-hdfs\2.2.0\hadoop-hdfs-2.2.0.jar;E:\mavenrepository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;E:\mavenrepository\org\apache\hbase\hbase-hadoop-compat\0.98.4-hadoop2\hbase-hadoop-compat-0.98.4-hadoop2.jar;E:\mavenrepository\org\apache\hadoop\hadoop-client\2.4.0\hadoop-client-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-mapreduce-client-app\2.4.0\hadoop-mapreduce-client-app-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-mapreduce-client-common\2.4.0\hadoop-mapreduce-client-common-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-yarn-client\2.4.0\hadoop-yarn-client-2.4.0.jar;E:\mavenrepository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;E:\mavenrepository\org\apache\hadoop\hadoop-yarn-server-common\2.4.0\hadoop-yarn-server-common-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.4.0\hadoop-mapreduce-client-shuffle-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-yarn-api\2.4.0\hadoop-yarn-api-2.4.0.jar;E:\mavenrepository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.4.0\hadoop-mapreduce-client-jobclient-2.4.0.jar;C:\Program Files\Java\jdk1.8.0_60\lib\tools.jar
2015-12-17 16:48:45  [ main:376 ] - [ INFO ]  Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_60\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jre1.8.0_66/bin/server;C:/Program Files/Java/jre1.8.0_66/bin;C:/Program Files/Java/jre1.8.0_66/lib/amd64;C:\ProgramData\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\NetSarang;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Java\jdk1.8.0_60\bin;D:\developtools\maven\apache-maven-3.2.3-bin\apache-maven-3.2.3\bin;D:\Program Files (x86)\Git\cmd;D:\snapshot;D:\Program Files\TortoiseSVN\bin;D:\developtools\apache-ant-1.9.4\bin;D:\Program Files (x86)\scala\bin;C:\Program Files (x86)\scala\bin;D:\Program Files (x86)\OpenVPN\bin;D:\developtools\eclipse64\eclipse;;.
2015-12-17 16:48:45  [ main:376 ] - [ INFO ]  Client environment:java.io.tmpdir=C:\Users\ADMINI~1.K5Y\AppData\Local\Temp\
2015-12-17 16:48:45  [ main:376 ] - [ INFO ]  Client environment:java.compiler=<NA>
2015-12-17 16:48:45  [ main:376 ] - [ INFO ]  Client environment:os.name=Windows 7
2015-12-17 16:48:45  [ main:376 ] - [ INFO ]  Client environment:os.arch=amd64
2015-12-17 16:48:45  [ main:376 ] - [ INFO ]  Client environment:os.version=6.1
2015-12-17 16:48:45  [ main:376 ] - [ INFO ]  Client environment:user.name=Administrator
2015-12-17 16:48:45  [ main:376 ] - [ INFO ]  Client environment:user.home=C:\Users\Administrator.K5YUPM1XIRO9YVM
2015-12-17 16:48:45  [ main:376 ] - [ INFO ]  Client environment:user.dir=E:\adunit\hadoop-tool
2015-12-17 16:48:45  [ main:377 ] - [ INFO ]  Initiating client connection, connectString=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181 sessionTimeout=30000 watcher=hconnection-0x2b552920, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure
2015-12-17 16:48:45  [ main:380 ] - [ DEBUG ]  zookeeper.disableAutoWatchReset is false
2015-12-17 16:48:45  [ main-SendThread(storm14669:2181):475 ] - [ INFO ]  Opening socket connection to server storm14669/192.168.146.69:2181. Will not attempt to authenticate using SASL (unknown error)
2015-12-17 16:48:45  [ main:477 ] - [ INFO ]  Process identifier=hconnection-0x2b552920 connecting to ZooKeeper ensemble=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181
2015-12-17 16:48:45  [ main-SendThread(storm14669:2181):482 ] - [ INFO ]  Socket connection established to storm14669/192.168.146.69:2181, initiating session
2015-12-17 16:48:45  [ main-SendThread(storm14669:2181):484 ] - [ DEBUG ]  Session establishment request sent on storm14669/192.168.146.69:2181
2015-12-17 16:48:45  [ main-SendThread(storm14669:2181):743 ] - [ INFO ]  Session establishment complete on server storm14669/192.168.146.69:2181, sessionid = 0x9515656863808a0, negotiated timeout = 30000
2015-12-17 16:48:45  [ main-EventThread:747 ] - [ DEBUG ]  hconnection-0x2b552920, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2015-12-17 16:48:45  [ main-EventThread:751 ] - [ DEBUG ]  hconnection-0x2b552920-0x9515656863808a0 connected
2015-12-17 16:48:45  [ main-SendThread(storm14669:2181):1044 ] - [ DEBUG ]  Reading reply sessionid:0x9515656863808a0, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,438132934429,0  request:: '/hbase-unsecure/hbaseid,F  response:: s{154655491313,438112239238,1432008035942,1449675376357,3,0,0,0,67,0,154655491313} 
2015-12-17 16:48:46  [ main-SendThread(storm14669:2181):1285 ] - [ DEBUG ]  Reading reply sessionid:0x9515656863808a0, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,438132934429,0  request:: '/hbase-unsecure/hbaseid,F  response:: #ffffffff000146d61737465723a36303030304fffffffef1ffffffffdffffff8b62553d50425546a2439666666343534382d643935652d343637352d626635652d623035626335363434353537,s{154655491313,438112239238,1432008035942,1449675376357,3,0,0,0,67,0,154655491313} 
2015-12-17 16:48:46  [ main:1517 ] - [ DEBUG ]  Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@13c10b87, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2015-12-17 16:48:46  [ main:1530 ] - [ INFO ]  Initiating client connection, connectString=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181 sessionTimeout=30000 watcher=catalogtracker-on-hconnection-0x2b552920, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure
2015-12-17 16:48:46  [ main:1533 ] - [ INFO ]  Process identifier=catalogtracker-on-hconnection-0x2b552920 connecting to ZooKeeper ensemble=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181
2015-12-17 16:48:46  [ main-SendThread(hadoop14691:2181):1534 ] - [ INFO ]  Opening socket connection to server hadoop14691/192.168.146.91:2181. Will not attempt to authenticate using SASL (unknown error)
2015-12-17 16:48:46  [ main:1536 ] - [ DEBUG ]  Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3b07a0d6
2015-12-17 16:48:46  [ main-SendThread(hadoop14691:2181):1541 ] - [ INFO ]  Socket connection established to hadoop14691/192.168.146.91:2181, initiating session
2015-12-17 16:48:46  [ main-SendThread(hadoop14691:2181):1541 ] - [ DEBUG ]  Session establishment request sent on hadoop14691/192.168.146.91:2181
2015-12-17 16:48:46  [ main-SendThread(hadoop14691:2181):1782 ] - [ INFO ]  Session establishment complete on server hadoop14691/192.168.146.91:2181, sessionid = 0x3515656862ddc22, negotiated timeout = 30000
2015-12-17 16:48:46  [ main-EventThread:1785 ] - [ DEBUG ]  catalogtracker-on-hconnection-0x2b552920, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2015-12-17 16:48:46  [ main-EventThread:1787 ] - [ DEBUG ]  catalogtracker-on-hconnection-0x2b552920-0x3515656862ddc22 connected
2015-12-17 16:48:46  [ main-SendThread(hadoop14691:2181):1789 ] - [ DEBUG ]  Reading reply sessionid:0x3515656862ddc22, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,438132934453,0  request:: '/hbase-unsecure/meta-region-server,T  response:: s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 16:48:46  [ main:1789 ] - [ DEBUG ]  catalogtracker-on-hconnection-0x2b552920-0x3515656862ddc22, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure Set watcher on existing znode=/hbase-unsecure/meta-region-server
2015-12-17 16:48:46  [ main-SendThread(hadoop14691:2181):1795 ] - [ DEBUG ]  Reading reply sessionid:0x3515656862ddc22, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,438132934454,0  request:: '/hbase-unsecure/meta-region-server,T  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffff8dffffffebffffffb3516fffffffd2ffffffb0650425546a19ac6861646f6f7031343631393010fffffff4ffffffd4318ffffffb1ffffffa9ffffff8bffffffbbffffff982a100,s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 16:48:46  [ main:1836 ] - [ INFO ]  hadoop.native.lib is deprecated. Instead, use io.native.lib.available
2015-12-17 16:48:46  [ main-SendThread(storm14669:2181):1980 ] - [ DEBUG ]  Reading reply sessionid:0x9515656863808a0, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,438132934456,0  request:: '/hbase-unsecure/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffff8dffffffebffffffb3516fffffffd2ffffffb0650425546a19ac6861646f6f7031343631393010fffffff4ffffffd4318ffffffb1ffffffa9ffffff8bffffffbbffffff982a100,s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 16:48:47  [ main:2106 ] - [ DEBUG ]  Use SIMPLE authentication for service ClientService, sasl=false
2015-12-17 16:48:47  [ main:2114 ] - [ DEBUG ]  Connecting to hadoop146190/192.168.146.190:60020
2015-12-17 16:48:47  [ IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator:2126 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: starting, connections 1
2015-12-17 16:48:47  [ main:2136 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 0 method_name: "Scan" request_param: true
2015-12-17 16:48:47  [ IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator:2196 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 0, totalSize: 20 bytes
2015-12-17 16:48:47  [ main:2201 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 1 method_name: "Scan" request_param: true priority: 100
2015-12-17 16:48:47  [ IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator:2221 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 1 cell_block_meta { length: 5316 }, totalSize: 5363 bytes
2015-12-17 16:48:47  [ main:2239 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 2 method_name: "Scan" request_param: true
2015-12-17 16:48:47  [ IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator:2266 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 2, totalSize: 16 bytes
2015-12-17 16:48:47  [ main:2291 ] - [ DEBUG ]  Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3b07a0d6
2015-12-17 16:48:47  [ main:2291 ] - [ DEBUG ]  Closing session: 0x3515656862ddc22
2015-12-17 16:48:47  [ main:2291 ] - [ DEBUG ]  Closing client for session: 0x3515656862ddc22
2015-12-17 16:48:47  [ main-SendThread(hadoop14691:2181):2297 ] - [ DEBUG ]  Reading reply sessionid:0x3515656862ddc22, packet:: clientPath:null serverPath:null finished:false header:: 3,-11  replyHeader:: 3,438132934472,0  request:: null response:: null
2015-12-17 16:48:47  [ main:2297 ] - [ DEBUG ]  Disconnecting client for session: 0x3515656862ddc22
2015-12-17 16:48:47  [ main:2297 ] - [ INFO ]  Session: 0x3515656862ddc22 closed
2015-12-17 16:48:47  [ main-EventThread:2297 ] - [ INFO ]  EventThread shut down
2015-12-17 16:48:47  [ main-SendThread(storm14669:2181):2306 ] - [ DEBUG ]  Reading reply sessionid:0x9515656863808a0, packet:: clientPath:null serverPath:null finished:false header:: 4,3  replyHeader:: 4,438132934472,0  request:: '/hbase-unsecure,F  response:: s{90194321419,90194321419,1410501665281,1410501665281,0,83,0,0,0,15,438112239529} 
2015-12-17 16:48:47  [ main-SendThread(storm14669:2181):2312 ] - [ DEBUG ]  Reading reply sessionid:0x9515656863808a0, packet:: clientPath:null serverPath:null finished:false header:: 5,4  replyHeader:: 5,438132934472,0  request:: '/hbase-unsecure/master,F  response:: #ffffffff000146d61737465723a36303030304bffffff95ffffffb0ffffffb4ffffff9947ff50425546a18ab6861646f6f70313436393110ffffffe0ffffffd4318ffffffc3fffffff6ffffff8affffffbbffffff982a100,s{438112239199,438112239199,1449675375401,1449675375401,0,0,0,671412749073908824,57,0,438112239199} 
2015-12-17 16:48:47  [ main:2318 ] - [ DEBUG ]  Use SIMPLE authentication for service MasterService, sasl=false
2015-12-17 16:48:47  [ main:2318 ] - [ DEBUG ]  Connecting to hadoop14691/192.168.146.91:60000
2015-12-17 16:48:47  [ IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator:2325 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator: starting, connections 2
2015-12-17 16:48:47  [ main:2325 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator: wrote request header call_id: 3 method_name: "IsMasterRunning" request_param: true
2015-12-17 16:48:47  [ IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator:2470 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator: got response header call_id: 3, totalSize: 6 bytes
2015-12-17 16:48:47  [ main:2581 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator: wrote request header call_id: 4 method_name: "CreateTable" request_param: true
2015-12-17 16:48:47  [ IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator:2828 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop14691/192.168.146.91:60000 from Administrator: got response header call_id: 4, totalSize: 4 bytes
2015-12-17 16:48:47  [ main-SendThread(storm14669:2181):2860 ] - [ DEBUG ]  Reading reply sessionid:0x9515656863808a0, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,438132934497,0  request:: '/hbase-unsecure/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffff8dffffffebffffffb3516fffffffd2ffffffb0650425546a19ac6861646f6f7031343631393010fffffff4ffffffd4318ffffffb1ffffffa9ffffff8bffffffbbffffff982a100,s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 16:48:47  [ main:2863 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 5 method_name: "Scan" request_param: true
2015-12-17 16:48:47  [ IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator:2866 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 5, totalSize: 20 bytes
2015-12-17 16:48:47  [ main:2867 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 6 method_name: "Scan" request_param: true priority: 100
2015-12-17 16:48:47  [ IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator:2886 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 6 cell_block_meta { length: 5769 }, totalSize: 5818 bytes
2015-12-17 16:48:47  [ main:2888 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 7 method_name: "Scan" request_param: true
2015-12-17 16:48:47  [ IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator:2933 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 7, totalSize: 16 bytes
2015-12-17 16:48:47  [ main:2937 ] - [ INFO ]  Initiating client connection, connectString=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181 sessionTimeout=30000 watcher=catalogtracker-on-hconnection-0x2b552920, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure
2015-12-17 16:48:47  [ main:2942 ] - [ INFO ]  Process identifier=catalogtracker-on-hconnection-0x2b552920 connecting to ZooKeeper ensemble=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181
2015-12-17 16:48:47  [ main:2943 ] - [ DEBUG ]  Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@5403f35f
2015-12-17 16:48:47  [ main-SendThread(hadoop14691:2181):2943 ] - [ INFO ]  Opening socket connection to server hadoop14691/192.168.146.91:2181. Will not attempt to authenticate using SASL (unknown error)
2015-12-17 16:48:47  [ main-SendThread(hadoop14691:2181):2948 ] - [ INFO ]  Socket connection established to hadoop14691/192.168.146.91:2181, initiating session
2015-12-17 16:48:47  [ main-SendThread(hadoop14691:2181):2948 ] - [ DEBUG ]  Session establishment request sent on hadoop14691/192.168.146.91:2181
2015-12-17 16:48:47  [ main-SendThread(hadoop14691:2181):3030 ] - [ INFO ]  Session establishment complete on server hadoop14691/192.168.146.91:2181, sessionid = 0x3515656862ddc23, negotiated timeout = 30000
2015-12-17 16:48:47  [ main-EventThread:3030 ] - [ DEBUG ]  catalogtracker-on-hconnection-0x2b552920, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2015-12-17 16:48:47  [ main-EventThread:3033 ] - [ DEBUG ]  catalogtracker-on-hconnection-0x2b552920-0x3515656862ddc23 connected
2015-12-17 16:48:47  [ main-SendThread(hadoop14691:2181):3035 ] - [ DEBUG ]  Reading reply sessionid:0x3515656862ddc23, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,438132934506,0  request:: '/hbase-unsecure/meta-region-server,T  response:: s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 16:48:47  [ main:3035 ] - [ DEBUG ]  catalogtracker-on-hconnection-0x2b552920-0x3515656862ddc23, quorum=storm14664:2181,storm14656:2181,hadoop14691:2181,hadoop146066.ysc.com:2181,storm14669:2181,storm14668:2181,storm14667:2181,storm14665:2181, baseZNode=/hbase-unsecure Set watcher on existing znode=/hbase-unsecure/meta-region-server
2015-12-17 16:48:47  [ main-SendThread(hadoop14691:2181):3044 ] - [ DEBUG ]  Reading reply sessionid:0x3515656862ddc23, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,438132934506,0  request:: '/hbase-unsecure/meta-region-server,T  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffff8dffffffebffffffb3516fffffffd2ffffffb0650425546a19ac6861646f6f7031343631393010fffffff4ffffffd4318ffffffb1ffffffa9ffffff8bffffffbbffffff982a100,s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 16:48:47  [ main-SendThread(storm14669:2181):3061 ] - [ DEBUG ]  Reading reply sessionid:0x9515656863808a0, packet:: clientPath:null serverPath:null finished:false header:: 7,4  replyHeader:: 7,438132934508,0  request:: '/hbase-unsecure/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3630303230ffffff8dffffffebffffffb3516fffffffd2ffffffb0650425546a19ac6861646f6f7031343631393010fffffff4ffffffd4318ffffffb1ffffffa9ffffff8bffffffbbffffff982a100,s{438112239529,438112239529,1449675385209,1449675385209,0,0,0,0,64,0,438112239529} 
2015-12-17 16:48:47  [ main:3067 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 8 method_name: "Scan" request_param: true
2015-12-17 16:48:47  [ IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator:3072 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 8, totalSize: 20 bytes
2015-12-17 16:48:47  [ main:3073 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 9 method_name: "Scan" request_param: true priority: 100
2015-12-17 16:48:48  [ IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator:3091 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 9 cell_block_meta { length: 5769 }, totalSize: 5818 bytes
2015-12-17 16:48:48  [ main:3092 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: wrote request header call_id: 10 method_name: "Scan" request_param: true
2015-12-17 16:48:48  [ IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator:3137 ] - [ DEBUG ]  IPC Client (299644693) connection to hadoop146190/192.168.146.190:60020 from Administrator: got response header call_id: 10, totalSize: 16 bytes
2015-12-17 16:48:48  [ main:3137 ] - [ DEBUG ]  Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@5403f35f
2015-12-17 16:48:48  [ main:3137 ] - [ DEBUG ]  Closing session: 0x3515656862ddc23
2015-12-17 16:48:48  [ main:3137 ] - [ DEBUG ]  Closing client for session: 0x3515656862ddc23
2015-12-17 16:48:48  [ main-SendThread(hadoop14691:2181):3146 ] - [ DEBUG ]  Reading reply sessionid:0x3515656862ddc23, packet:: clientPath:null serverPath:null finished:false header:: 3,-11  replyHeader:: 3,438132934513,0  request:: null response:: null
2015-12-17 16:48:48  [ main:3147 ] - [ DEBUG ]  Disconnecting client for session: 0x3515656862ddc23
2015-12-17 16:48:48  [ main:3147 ] - [ INFO ]  Session: 0x3515656862ddc23 closed
2015-12-17 16:48:48  [ main-EventThread:3147 ] - [ INFO ]  EventThread shut down
2015-12-17 16:48:48  [ main-SendThread(storm14669:2181):3154 ] - [ DEBUG ]  Reading reply sessionid:0x9515656863808a0, packet:: clientPath:null serverPath:null finished:false header:: 8,4  replyHeader:: 8,438132934513,0  request:: '/hbase-unsecure/table/adunit,F  response:: #ffffffff000146d61737465723a3630303030ffffff88ffffffe54fffffff94cfffffff8dffffff8e5042554680,s{438132934486,438132934492,1450342140083,1450342140233,2,0,0,0,31,0,438132934486} 
